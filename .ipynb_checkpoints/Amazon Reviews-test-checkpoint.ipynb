{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os\n",
    "import csv\n",
    "import os, re, itertools\n",
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem.porter import *\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from scipy.special import softmax\n",
    "import urllib.request\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    TFAutoModelForSequenceClassification,\n",
    "    AutoTokenizer, \n",
    "    pipeline\n",
    ")\n",
    "BASE_DIR=\"C:\\\\Users\\\\AYODE\\\\OneDrive\\\\Desktop\\\\Webcrawler\\\\analytics\\\\models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-5909a31ec99e>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  amazon_df[\"number_of_reviews\"] = amazon_df[\"reviews_by_comments\"].apply(lambda x: len(x))\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('amazon.csv')\n",
    "df.head()\n",
    "\n",
    "amazon_df = df[['id', 'SourceUserId', 'reviews_by_rating', 'reviews_by_comments', 'average_rating', \n",
    "    'number_of_reviews', 'number_of_rating', 'MentionEnglish', 'Sentiment', 'KeyTerms', 'Quantity', \n",
    "    'Growth', 'short_description', 'price', 'product_description',  'TopicLevel1Id', 'TopicLevel2Id', 'TopicLevel3Id']]\n",
    "amazon_df[\"number_of_reviews\"] = amazon_df[\"reviews_by_comments\"].apply(lambda x: len(x))\n",
    "\n",
    "reviews_df = amazon_df.copy()\n",
    "reviews_df_dict = reviews_df.drop(columns=[\"id\"]).to_dict(\"records\")\n",
    "reviews_df_list = []\n",
    "for rec in reviews_df_dict:\n",
    "    reviews = rec.pop('reviews_by_comments')\n",
    "    reviews = literal_eval(reviews)\n",
    "    for rev in reviews:\n",
    "        if not rev.get(\"comment_rating\"): continue\n",
    "        reviews_df_list.append({**rec.copy(), **rev})\n",
    "\n",
    "reviews_df = pd.DataFrame(reviews_df_list)\n",
    "\n",
    "\n",
    "# Preprocess text (username and link placeholders)\n",
    "# raw_inputs = [preprocess(reviews_df.iloc[7][\"comments\"])]\n",
    "def preprocess(text):\n",
    "    if not text: return \" \"\n",
    "    pattern = re.compile(r'<.*?>')  # tags look like <...>\n",
    "    text = pattern.sub('', text)  # replace them with blank\n",
    "    text = text.lower() # Case Normalization\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE NaN VALUES AND EMPTY STRINGS:\n",
    "df.dropna(inplace=True)\n",
    "reviews_df = reviews_df[reviews_df['comments'].notna()]\n",
    "reviews_df = reviews_df[reviews_df['comments'].notnull()]\n",
    "reviews_df = reviews_df[reviews_df['average_rating'].notna()]\n",
    "reviews_df.rename(columns={\"comment_rating\": \"label\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "925"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceUserId</th>\n",
       "      <th>reviews_by_rating</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>number_of_rating</th>\n",
       "      <th>MentionEnglish</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>KeyTerms</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Growth</th>\n",
       "      <th>short_description</th>\n",
       "      <th>price</th>\n",
       "      <th>product_description</th>\n",
       "      <th>TopicLevel1Id</th>\n",
       "      <th>TopicLevel2Id</th>\n",
       "      <th>TopicLevel3Id</th>\n",
       "      <th>user</th>\n",
       "      <th>comments</th>\n",
       "      <th>reaction</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B004N5J568</td>\n",
       "      <td>[{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4836</td>\n",
       "      <td>182.0</td>\n",
       "      <td>Scharffen Berger Natural Unsweetened Cocoa Pow...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>Qualify as Gluten Free using Standards propose...</td>\n",
       "      <td>18.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Susie's</td>\n",
       "      <td>So glad I discovered Scharffen Berger.  For a ...</td>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B004N5J568</td>\n",
       "      <td>[{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4836</td>\n",
       "      <td>182.0</td>\n",
       "      <td>Scharffen Berger Natural Unsweetened Cocoa Pow...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>Qualify as Gluten Free using Standards propose...</td>\n",
       "      <td>18.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aja</td>\n",
       "      <td>I have been trying many different brands of ch...</td>\n",
       "      <td>17</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B004N5J568</td>\n",
       "      <td>[{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4836</td>\n",
       "      <td>182.0</td>\n",
       "      <td>Scharffen Berger Natural Unsweetened Cocoa Pow...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>Qualify as Gluten Free using Standards propose...</td>\n",
       "      <td>18.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TonyD</td>\n",
       "      <td>Tried many types of cocoa to make chocolate an...</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B004N5J568</td>\n",
       "      <td>[{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4836</td>\n",
       "      <td>182.0</td>\n",
       "      <td>Scharffen Berger Natural Unsweetened Cocoa Pow...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>Qualify as Gluten Free using Standards propose...</td>\n",
       "      <td>18.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sharron</td>\n",
       "      <td>We find this cocoa powder  has a delicate text...</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B004N5J568</td>\n",
       "      <td>[{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4836</td>\n",
       "      <td>182.0</td>\n",
       "      <td>Scharffen Berger Natural Unsweetened Cocoa Pow...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>Qualify as Gluten Free using Standards propose...</td>\n",
       "      <td>18.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wizdum</td>\n",
       "      <td>Baked a gourmet gluten free chocolate cake wit...</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SourceUserId                                  reviews_by_rating  \\\n",
       "0   B004N5J568  [{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...   \n",
       "1   B004N5J568  [{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...   \n",
       "2   B004N5J568  [{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...   \n",
       "3   B004N5J568  [{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...   \n",
       "4   B004N5J568  [{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...   \n",
       "\n",
       "   average_rating  number_of_reviews  number_of_rating  \\\n",
       "0             4.9               4836             182.0   \n",
       "1             4.9               4836             182.0   \n",
       "2             4.9               4836             182.0   \n",
       "3             4.9               4836             182.0   \n",
       "4             4.9               4836             182.0   \n",
       "\n",
       "                                      MentionEnglish  Sentiment KeyTerms  \\\n",
       "0  Scharffen Berger Natural Unsweetened Cocoa Pow...        NaN    cocoa   \n",
       "1  Scharffen Berger Natural Unsweetened Cocoa Pow...        NaN    cocoa   \n",
       "2  Scharffen Berger Natural Unsweetened Cocoa Pow...        NaN    cocoa   \n",
       "3  Scharffen Berger Natural Unsweetened Cocoa Pow...        NaN    cocoa   \n",
       "4  Scharffen Berger Natural Unsweetened Cocoa Pow...        NaN    cocoa   \n",
       "\n",
       "   Quantity  Growth                                  short_description  price  \\\n",
       "0       255       0  Qualify as Gluten Free using Standards propose...  18.99   \n",
       "1       255       0  Qualify as Gluten Free using Standards propose...  18.99   \n",
       "2       255       0  Qualify as Gluten Free using Standards propose...  18.99   \n",
       "3       255       0  Qualify as Gluten Free using Standards propose...  18.99   \n",
       "4       255       0  Qualify as Gluten Free using Standards propose...  18.99   \n",
       "\n",
       "   product_description  TopicLevel1Id  TopicLevel2Id  TopicLevel3Id     user  \\\n",
       "0                  NaN            NaN            NaN            NaN  Susie's   \n",
       "1                  NaN            NaN            NaN            NaN      Aja   \n",
       "2                  NaN            NaN            NaN            NaN    TonyD   \n",
       "3                  NaN            NaN            NaN            NaN  sharron   \n",
       "4                  NaN            NaN            NaN            NaN   Wizdum   \n",
       "\n",
       "                                            comments  reaction  label  \n",
       "0  So glad I discovered Scharffen Berger.  For a ...         8    5.0  \n",
       "1  I have been trying many different brands of ch...        17    5.0  \n",
       "2  Tried many types of cocoa to make chocolate an...         4    5.0  \n",
       "3  We find this cocoa powder  has a delicate text...         2    5.0  \n",
       "4  Baked a gourmet gluten free chocolate cake wit...         1    5.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOPIC LEVELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    }
   ],
   "source": [
    "BART_MODEL = os.path.join(BASE_DIR, \"facebook\", \"bart-large-mnli\")\n",
    "bart_classifier = pipeline(\"zero-shot-classification\", model=BART_MODEL)\n",
    "\n",
    "DISTILBERT_MODEL = os.path.join(BASE_DIR, \"typeform\", \"distilbert-base-uncased-mnli\")\n",
    "distilbert_classifier = pipeline(\"zero-shot-classification\", model=DISTILBERT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ROBERTA_MODEL = os.path.join(BASE_DIR, \"joeddav\", \"xlm-roberta-large-xnli\")\n",
    "VALHALLA_MODEL = os.path.join(BASE_DIR, \"valhalla\", \"distilbart-mnli-12-9\")\n",
    "valhalla_classifier = pipeline(\"zero-shot-classification\", model=VALHALLA_MODEL, tokenizer=\"valhalla/distilbart-mnli-12-9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bart_topic_level(sequence_to_classify, candidate_labels):\n",
    "    response = bart_classifier(sequence_to_classify, candidate_labels)\n",
    "    scores = response['scores']\n",
    "    labels = response['labels']\n",
    "    topic_levels = dict([(c, s) for c, s in zip(labels, scores)])\n",
    "    \n",
    "    return topic_levels\n",
    "\n",
    "def distilbert_topic_level(sequence_to_classify, candidate_labels):\n",
    "    response = distilbert_classifier(sequence_to_classify, candidate_labels)\n",
    "    scores = response['scores']\n",
    "    labels = response['labels']\n",
    "    topic_levels = dict([(c, s) for c, s in zip(labels, scores)])\n",
    "    \n",
    "    return topic_levels\n",
    "\n",
    "def valhalla_topic_level(sequence_to_classify, candidate_labels):\n",
    "    response = valhalla_classifier(sequence_to_classify, candidate_labels)\n",
    "    scores = response['scores']\n",
    "    labels = response['labels']\n",
    "    topic_levels = dict([(c, s) for c, s in zip(labels, scores)])\n",
    "    \n",
    "    return topic_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMBINED_TOPIC_LEVELS = {\n",
    "  \"Product Components\": {\n",
    "    \"Id\": 1,\n",
    "    \"topic_twos\": {\n",
    "      \"Device Feedback\": { \"Id\": 1, \"topic_threes\": {} },\n",
    "      \"Display\": { \"Id\": 2, \"topic_threes\": {} },\n",
    "      \"Mod\": { \"Id\": 3, \"topic_threes\": {} },\n",
    "      \"Charger\": { \"Id\": 4, \"topic_threes\": {} },\n",
    "      \"Heating Element\": {\n",
    "        \"Id\": 5,\n",
    "        \"topic_threes\": { \"Cartomizer\": 1, \"Coil\": 2, \"Atomizer\": 3 }\n",
    "      },\n",
    "      \"Clearomize/Tank\": { \"Id\": 6, \"topic_threes\": {} },\n",
    "      \"Battery\": { \"Id\": 7, \"topic_threes\": { \"Charging\": 4, \"Life\": 5 } },\n",
    "      \"LED Function\": { \"Id\": 8, \"topic_threes\": {} },\n",
    "      \"Misc(buttons,Magnets,Lid)\": { \"Id\": 9, \"topic_threes\": {} }\n",
    "    }\n",
    "  },\n",
    "  \"Experience\": {\n",
    "    \"Id\": 2,\n",
    "    \"topic_twos\": {\n",
    "      \"Design\": {\n",
    "        \"Id\": 10,\n",
    "        \"topic_threes\": { \"Ease of Use\": 6, \"Look\": 7, \"Ergomonic/Feel\": 8 }\n",
    "      },\n",
    "      \"Vapour Delivery\": { \"Id\": 11, \"topic_threes\": {} },\n",
    "      \"Taste Experience\": { \"Id\": 12, \"topic_threes\": {} },\n",
    "      \"Quantity\": { \"Id\": 13, \"topic_threes\": {} },\n",
    "      \"Integrity\": {\n",
    "        \"Id\": 14,\n",
    "        \"topic_threes\": { \"Leakage\": 9, \"Damage\": 10, \"Quality/Durability\": 11 }\n",
    "      },\n",
    "      \"Packaging\": { \"Id\": 15, \"topic_threes\": {} },\n",
    "      \"Length of Use\": { \"Id\": 16, \"topic_threes\": {} },\n",
    "      \"Flavour/Smell\": { \"Id\": 18, \"topic_threes\": {} },\n",
    "      \"Nicotine\": { \"Id\": 20, \"topic_threes\": {} }\n",
    "    }\n",
    "  },\n",
    "  \"Value and Service\": {\n",
    "    \"Id\": 3,\n",
    "    \"topic_twos\": {\n",
    "      \"Price\": { \"Id\": 21, \"topic_threes\": {} },\n",
    "      \"Customer Service\": { \"Id\": 22, \"topic_threes\": {} },\n",
    "      \"Website/Service\": { \"Id\": 23, \"topic_threes\": {} },\n",
    "      \"Counterfeit\": { \"Id\": 24, \"topic_threes\": {} },\n",
    "      \"Company\": { \"Id\": 26, \"topic_threes\": {} },\n",
    "      \"Delivery\": { \"Id\": 27, \"topic_threes\": {} },\n",
    "      \"Availability\": { \"Id\": 28, \"topic_threes\": {} }\n",
    "    }\n",
    "  },\n",
    "  \"Health and Safety\": {\n",
    "    \"Id\": 4,\n",
    "    \"topic_twos\": {\n",
    "      \"Health\": {\n",
    "        \"Id\": 29,\n",
    "        \"topic_threes\": {\n",
    "          \"Allergic Reactions\": 12,\n",
    "          \"Palpitations\": 13,\n",
    "          \"Breathing\": 14,\n",
    "          \"Others\": 15\n",
    "        }\n",
    "      },\n",
    "      \"Safety\": {\n",
    "        \"Id\": 30,\n",
    "        \"topic_threes\": { \"Overheating\": 17, \"Burns\": 18, \"Others\": 19 }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"General Feedback\": { \"Id\": 5, \"topic_twos\": {} },\n",
    "  \"Others\": { \"Id\": 6, \"topic_twos\": {} }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_topic_levels(\n",
    "    sequence_to_classify = \"one day I will see the world\",\n",
    "    candidate_labels = ['travel', 'cooking', 'dancing']\n",
    "):\n",
    "    bart_score = bart_topic_level(sequence_to_classify, candidate_labels)\n",
    "    distilbert_score = distilbert_topic_level(sequence_to_classify, candidate_labels)\n",
    "    roberta_score = valhalla_topic_level(sequence_to_classify, candidate_labels)\n",
    "\n",
    "    candidate_labels_positions = {}\n",
    "    bart_score_labels = list(bart_score.keys())\n",
    "    distilbert_score_labels = list(distilbert_score.keys())\n",
    "    roberta_score_labels = list(roberta_score.keys())\n",
    "    for item in candidate_labels:\n",
    "        x = bart_score_labels.index(item)\n",
    "        y = distilbert_score_labels.index(item)\n",
    "        z = roberta_score_labels.index(item)\n",
    "        candidate_labels_positions[item] = [x,y,z]\n",
    "            \n",
    "    label_counter ={\n",
    "        lab: Counter(positions)\n",
    "        for lab, positions in candidate_labels_positions.items()\n",
    "    }\n",
    "        \n",
    "    # first iteration\n",
    "\n",
    "    possible_labels ={\n",
    "        lab: item\n",
    "        for lab, item in label_counter.items()\n",
    "        if item.most_common(1)[0][0] == 0\n",
    "    }\n",
    "\n",
    "    if len(possible_labels) == 1: return list(possible_labels.keys())[0]\n",
    "\n",
    "    possible_labels ={\n",
    "        lab: item\n",
    "        for lab, item in label_counter.items()\n",
    "        if item.most_common(1)[0][0] == 0 and 1 in item\n",
    "    }\n",
    "\n",
    "    if len(possible_labels) == 1: return list(possible_labels.keys())[0]\n",
    "\n",
    "    cur_max_value = 0\n",
    "    result = []\n",
    "    for k, v in possible_labels.items():\n",
    "        if v[1] > cur_max_value: \n",
    "            result.clear()\n",
    "            result.append(k)\n",
    "            cur_max_value = v[1]\n",
    "            continue\n",
    "        if v[1] == cur_max_value: \n",
    "            result.append(k)\n",
    "\n",
    "    if len(result) == 1: return result[0]\n",
    "\n",
    "    if result: return random.choice(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_one_labels = list(COMBINED_TOPIC_LEVELS.keys())\n",
    "sequence_to_classify = \"Dear Mainstreet Mojo: Thank you for sending the Scharffen Cocoa. I was SO looking forward to enjoying it.  It is my favorite cocoa.  Sadly, the packaging was faulty.  Cocoa is spilled inside the plastic bag holding the two canisters.  The lids for both cans were open.  I don't feel safe using the product.  I'd like to re-order it, but would like to hear from you first to know that issue will be resolved.  Many thanks.  JW Read more\"\n",
    "TopicLevel1Label = evaluate_topic_levels(sequence_to_classify, candidate_one_labels)\n",
    "TopicLevel1Id = COMBINED_TOPIC_LEVELS[TopicLevel1Label]['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Value and Service'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TopicLevel1Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Product Components',\n",
       " 'Experience',\n",
       " 'Value and Service',\n",
       " 'Health and Safety',\n",
       " 'General Feedback',\n",
       " 'Others']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_one_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Dear Mainstreet Mojo: Thank you for sending the Scharffen Cocoa. I was SO looking forward to enjoying it.  It is my favorite cocoa.  Sadly, the packaging was faulty.  Cocoa is spilled inside the plastic bag holding the two canisters.  The lids for both cans were open.  I don't feel safe using the product.  I'd like to re-order it, but would like to hear from you first to know that issue will be resolved.  Many thanks.  JW Read more\""
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_to_classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Value and Service': 0.28007641434669495,\n",
       " 'Experience': 0.25472521781921387,\n",
       " 'General Feedback': 0.19591999053955078,\n",
       " 'Health and Safety': 0.09458401054143906,\n",
       " 'Product Components': 0.08749126642942429,\n",
       " 'Others': 0.08720310032367706}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart_topic_level(sequence_to_classify, candidate_one_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Health and Safety': 0.24655403196811676,\n",
       " 'Value and Service': 0.1854991912841797,\n",
       " 'Experience': 0.18226946890354156,\n",
       " 'Others': 0.1588033139705658,\n",
       " 'Product Components': 0.12272701412439346,\n",
       " 'General Feedback': 0.10414694994688034}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbert_topic_level(sequence_to_classify, candidate_one_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'General Feedback': 0.2958184778690338,\n",
       " 'Experience': 0.2695012092590332,\n",
       " 'Value and Service': 0.1820710152387619,\n",
       " 'Product Components': 0.09436516463756561,\n",
       " 'Health and Safety': 0.08052045106887817,\n",
       " 'Others': 0.07772375643253326}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valhalla_topic_level(sequence_to_classify, candidate_one_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Value and Service'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_topic_levels(sequence_to_classify,candidate_one_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'urgent': 0.5036358833312988,\n",
       " 'phone': 0.4787992537021637,\n",
       " 'computer': 0.012600314803421497,\n",
       " 'not urgent': 0.0026557822711765766,\n",
       " 'tablet': 0.0023087698500603437}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sequence_to_classify = \"one day I will see the world\",\n",
    "# candidate_labels = ['travel', 'cooking', 'dancing']\n",
    "sequence_to_classify = \"\"\n",
    "candidate_labels = [\"flavour\", \"sugar\", \"quantity\"]\n",
    "candidate_labels_2 = [\"flavour\", \"sugar\", \"quantity\"]\n",
    "bart_topic_level(sequence_to_classify, candidate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'phone': 0.8046278953552246,\n",
       " 'computer': 0.1348351389169693,\n",
       " 'not urgent': 0.026469016447663307,\n",
       " 'urgent': 0.02374200150370598,\n",
       " 'tablet': 0.010325913317501545}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbert_topic_level(sequence_to_classify, candidate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'phone': 0.6870530247688293,\n",
       " 'urgent': 0.27277669310569763,\n",
       " 'computer': 0.03387346491217613,\n",
       " 'tablet': 0.0033401884138584137,\n",
       " 'not urgent': 0.0029565419536083937}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valhalla_topic_level(sequence_to_classify, candidate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "from collections import Counter\n",
    "\n",
    "def evaluate_topic_levels(\n",
    "    sequence_to_classify = \"one day I will see the world\",\n",
    "    candidate_labels = ['travel', 'cooking', 'dancing']\n",
    "):\n",
    "    bart_score = bart_topic_level(sequence_to_classify, candidate_labels)\n",
    "    distilbert_score = distilbert_topic_level(sequence_to_classify, candidate_labels)\n",
    "    roberta_score = valhalla_topic_level(sequence_to_classify, candidate_labels)\n",
    "\n",
    "    candidate_labels_positions = {}\n",
    "    bart_score_labels = list(bart_score.keys())\n",
    "    distilbert_score_labels = list(distilbert_score.keys())\n",
    "    roberta_score_labels = list(roberta_score.keys())\n",
    "    for item in candidate_labels:\n",
    "        x = bart_score_labels.index(item)\n",
    "        y = distilbert_score_labels.index(item)\n",
    "        z = roberta_score_labels.index(item)\n",
    "        candidate_labels_positions[item] = [x,y,z]\n",
    "            \n",
    "    label_counter ={\n",
    "        lab: Counter(positions)\n",
    "        for lab, positions in candidate_labels_positions.items()\n",
    "    }\n",
    "        \n",
    "    # first iteration\n",
    "\n",
    "    possible_labels ={\n",
    "        lab: item\n",
    "        for lab, item in label_counter.items()\n",
    "        if item.most_common(1)[0][0] == 0\n",
    "    }\n",
    "\n",
    "    if len(possible_labels) == 1: return list(possible_labels.keys())[0]\n",
    "\n",
    "    possible_labels ={\n",
    "        lab: item\n",
    "        for lab, item in label_counter.items()\n",
    "        if item.most_common(1)[0][0] == 0 and 1 in item\n",
    "    }\n",
    "\n",
    "    if len(possible_labels) == 1: return list(possible_labels.keys())[0]\n",
    "\n",
    "    cur_max_value = 0\n",
    "    result = []\n",
    "    for k, v in possible_labels.items():\n",
    "        if v[1] > cur_max_value: \n",
    "            result.clear()\n",
    "            result.append(k)\n",
    "            cur_max_value = v[1]\n",
    "            continue\n",
    "        if v[1] == cur_max_value: \n",
    "            result.append(k)\n",
    "\n",
    "    if len(result) == 1: return result[0]\n",
    "\n",
    "    if result: return random.choice(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'phone'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_topic_levels(sequence_to_classify, candidate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VADER's `SentimentIntensityAnalyzer()` takes in a string and returns a dictionary of scores in each of four categories:\n",
    "* negative\n",
    "* neutral\n",
    "* positive\n",
    "* compound *(computed by normalizing the scores above)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Dear Mainstreet Mojo: Thank you for sending the Scharffen Cocoa. I was SO looking forward to enjoying it.  It is my favorite cocoa.  Sadly, the packaging was faulty.  Cocoa is spilled inside the plastic bag holding the two canisters.  The lids for both cans were open.  I don't feel safe using the product.  I'd like to re-order it, but would like to hear from you first to know that issue will be resolved.  Many thanks.  JW Read more\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.iloc[7][\"comments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9413"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "VADER MODEL\n",
    "\"\"\"\n",
    "def vader_sentiment(text):\n",
    "    try:\n",
    "        text = preprocess(text)\n",
    "        sid = SentimentIntensityAnalyzer()\n",
    "        score_dict = sid.polarity_scores(text)\n",
    "        return score_dict['compound']\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "vader_sentiment(reviews_df.iloc[7][\"comments\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5540308952331543"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "ROBERTA MODEL\n",
    "\"\"\"\n",
    "\n",
    "task='sentiment'\n",
    "ROB_MODEL = os.path.join(BASE_DIR, \"cardiffnlp\", f\"twitter-roberta-base-{task}\")\n",
    "\n",
    "def roberta_sentiment(text):\n",
    "    try:\n",
    "        raw_inputs = [text]\n",
    "        classifier = pipeline(\"sentiment-analysis\", model=ROB_MODEL)\n",
    "        scores = classifier(raw_inputs)\n",
    "        if not scores:\n",
    "            return 0\n",
    "        comment_score = scores[0]\n",
    "        if comment_score['label'] == 'LABEL_2':\n",
    "            return comment_score[\"score\"]\n",
    "        elif comment_score['label'] == 'LABEL_0':\n",
    "            return (1 - comment_score[\"score\"])\n",
    "        else:\n",
    "            return comment_score[\"score\"]\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "res_rob = roberta_sentiment(reviews_df.iloc[7][\"comments\"])\n",
    "res_rob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2773059010505676"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "distilbert-base-uncased-finetuned-sst-2-english\n",
    "\n",
    "This model has 1,487,588 Downloads in the last one month\n",
    "\n",
    "It is a fine-tune checkpoint of DistilBERT-base-uncased, fine-tuned on SST-2. \n",
    "This model reaches an accuracy of 91.3 on the dev set (for comparison, Bert bert-base-uncased version \n",
    "reaches an accuracy of 92.7).\n",
    "\n",
    "url: https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english\n",
    "\"\"\"\n",
    "\n",
    "DIS_MODEL = os.path.join(BASE_DIR, \"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "def distilbert_sentiment(comment):\n",
    "    try:\n",
    "        raw_inputs = [comment]\n",
    "        classifier = pipeline(\"sentiment-analysis\", model=DIS_MODEL)\n",
    "        scores = classifier(raw_inputs)\n",
    "        if not scores:\n",
    "            return 0\n",
    "        comment_score = scores[0]\n",
    "        if comment_score['label'] == 'POSITIVE':\n",
    "            return comment_score[\"score\"]\n",
    "        else:\n",
    "            return (1 - comment_score[\"score\"])\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "res = distilbert_sentiment(reviews_df.iloc[7][\"comments\"])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def categorise_scores(val, vader=False):\n",
    "    if not vader:\n",
    "        if 0.8 <= val <= 1:\n",
    "            return 5\n",
    "        elif 0.6 <= val < 0.8:\n",
    "            return 4\n",
    "        elif 0.4 <= val < 0.6:\n",
    "            return 3\n",
    "        elif 0.2 <= val < 0.4:\n",
    "            return 2\n",
    "        elif 0 < val < 0.2:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        if val == 0:\n",
    "            return 0\n",
    "        elif 0.6 <= val <= 1:\n",
    "            return 5\n",
    "        elif 0.2 <= val < 0.6:\n",
    "            return 4\n",
    "        elif -0.2 <= val < 0.2:\n",
    "            return 3\n",
    "        elif -0.6 <= val < -0.2:\n",
    "            return 2\n",
    "        elif -1 <= val < -0.6:\n",
    "            return 1\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_sentiment(MentionEnglish, review=None):\n",
    "    MentionEnglish = preprocess(MentionEnglish)\n",
    "    review = preprocess(review)\n",
    "    if not MentionEnglish and not review: return 0\n",
    "    vader_scores = vader_sentiment(review) if review else vader_sentiment(MentionEnglish)\n",
    "    roberta_scores = roberta_sentiment(review) if review else roberta_sentiment(MentionEnglish)\n",
    "    distilbert_scores = distilbert_sentiment(review) if review else distilbert_sentiment(MentionEnglish)\n",
    "\n",
    "    vader_label = categorise_scores(vader_scores, vader=True)\n",
    "    roberta_label = categorise_scores(roberta_scores)\n",
    "    distilbert_label = categorise_scores(distilbert_scores)\n",
    "\n",
    "    labels = [vader_label, roberta_label, distilbert_label]\n",
    "    labels = [s for s in labels if s]\n",
    "    \n",
    "    if not labels: return 0\n",
    "    if len(labels) == 1: return labels[0]\n",
    "\n",
    "    label_counter = Counter(labels)\n",
    "\n",
    "    if 2 in label_counter.values() or 3 in label_counter.values():\n",
    "        return label_counter.most_common(1)[0][0]\n",
    "\n",
    "    if len(labels) == 2:\n",
    "        if distilbert_label != 0 and distilbert_label in labels:\n",
    "            return distilbert_label\n",
    "        elif roberta_label != 0 and roberta_label in labels:\n",
    "            return roberta_label\n",
    "        else:\n",
    "            return vader_label\n",
    "\n",
    "    pair_wise_labels = list(itertools.combinations(labels, 2))\n",
    "    dist = {\n",
    "        abs(pw[0]-pw[1]): pw\n",
    "        for pw in pair_wise_labels\n",
    "    }\n",
    "\n",
    "    print(dist)\n",
    "    sorted_labels = sorted(labels, reverse=False)\n",
    "    if len(dist) == 1:\n",
    "        return sorted_labels[1]\n",
    "\n",
    "    print(sorted_labels)\n",
    "    return sorted_labels[1]\n",
    "\n",
    "evaluate_sentiment(reviews_df.iloc[7][\"comments\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "MentionEnglish = preprocess(reviews_df.iloc[7][\"comments\"])\n",
    "review = ''\n",
    "vader_scores = vader_sentiment(review) if review else vader_sentiment(MentionEnglish)\n",
    "roberta_scores = roberta_sentiment(review) if review else roberta_sentiment(MentionEnglish)\n",
    "distilbert_scores = distilbert_sentiment(review) if review else distilbert_sentiment(MentionEnglish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_label = categorise_scores(vader_scores, vader=True)\n",
    "roberta_label = categorise_scores(roberta_scores)\n",
    "distilbert_label = categorise_scores(distilbert_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbert_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 3, 2]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [vader_label, roberta_label, distilbert_label]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({5: 1, 3: 1, 2: 1})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counter = Counter(labels)\n",
    "label_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 in label_counter.values() or 3 in label_counter.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: (5, 3), 3: (5, 2), 1: (3, 2)}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_wise_labels = list(itertools.combinations(labels, 2))\n",
    "dist = {\n",
    "    abs(pw[0]-pw[1]): pw\n",
    "    for pw in pair_wise_labels\n",
    "}\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 5]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_labels = sorted(labels, reverse=False)\n",
    "sorted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Scores, Sentiment and Labels to the DataFrame\n",
    "In this next section we'll add columns to the original DataFrame to store polarity_score dictionaries, extracted compound scores, and new \"pos/neg\" labels derived from the compound score. We'll use this last column to perform an accuracy test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_classes = {\n",
    "    1: \"Extremely bad\",\n",
    "    2: \"Bad\",\n",
    "    3: \"Okay\",\n",
    "    4: \"Good\",\n",
    "    5: \"Excellent\",\n",
    "}\n",
    "\n",
    "def assign_category(val, min_value, max_value):\n",
    "    if min_value >= 0 and max_value <= 1:\n",
    "        if 0.8 <= val <= 1:\n",
    "            return 5\n",
    "        elif 0.6 <= val < 0.8:\n",
    "            return 4\n",
    "        elif 0.4 <= val < 0.6:\n",
    "            return 3\n",
    "        elif 0.2 <= val < 0.4:\n",
    "            return 2\n",
    "        elif 0 < val < 0.2:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        if val == 0:\n",
    "            return 5\n",
    "        elif 0.6 <= val <= 1:\n",
    "            return 5\n",
    "        elif 0.2 <= val < 0.6:\n",
    "            return 4\n",
    "        elif -0.2 <= val < 0.2:\n",
    "            return 3\n",
    "        elif -0.6 <= val < -0.2:\n",
    "            return 2\n",
    "        elif -1 <= val < -0.6:\n",
    "            return 1\n",
    "\n",
    "    \n",
    "def categorise_scores(data_series):\n",
    "    max_value = data_series.max()\n",
    "    min_value = data_series.min()\n",
    "    return [\n",
    "        assign_category(val, min_value, max_value) for val in data_series\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df['vader_scores'] = reviews_df['comments'].apply(lambda review: vader_sentiment(review))\n",
    "reviews_df['roberta_scores'] = reviews_df['comments'].apply(lambda review: roberta_sentiment(review))\n",
    "reviews_df['microsoft_scores'] = microsoft_sentiment(reviews_df['MentionEnglish'], reviews_df['comments'])\n",
    "reviews_df['distilbert_scores'] = distilbert_sentiment(reviews_df['MentionEnglish'], reviews_df['comments'])\n",
    "# reviews_df['Sentiment'] = reviews_df['scores'].apply(lambda c: grade_scores(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df['vader_label'] = categorise_scores(reviews_df['vader_scores'])\n",
    "reviews_df['roberta_label'] = categorise_scores(reviews_df['roberta_scores'])\n",
    "reviews_df['microsoft_label'] = categorise_scores(reviews_df['microsoft_scores'])\n",
    "reviews_df['distilbert_label'] = categorise_scores(reviews_df['distilbert_scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceUserId</th>\n",
       "      <th>reviews_by_rating</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>number_of_rating</th>\n",
       "      <th>MentionEnglish</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>KeyTerms</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Growth</th>\n",
       "      <th>...</th>\n",
       "      <th>reaction</th>\n",
       "      <th>label</th>\n",
       "      <th>vader_scores</th>\n",
       "      <th>roberta_scores</th>\n",
       "      <th>microsoft_scores</th>\n",
       "      <th>distilbert_scores</th>\n",
       "      <th>vader_label</th>\n",
       "      <th>roberta_label</th>\n",
       "      <th>microsoft_label</th>\n",
       "      <th>distilbert_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B004N5J568</td>\n",
       "      <td>[{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4836</td>\n",
       "      <td>182.0</td>\n",
       "      <td>Scharffen Berger Natural Unsweetened Cocoa Pow...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9190</td>\n",
       "      <td>0.9526</td>\n",
       "      <td>0.691417</td>\n",
       "      <td>0.9989</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B004N5J568</td>\n",
       "      <td>[{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4836</td>\n",
       "      <td>182.0</td>\n",
       "      <td>Scharffen Berger Natural Unsweetened Cocoa Pow...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9767</td>\n",
       "      <td>0.7285</td>\n",
       "      <td>0.643807</td>\n",
       "      <td>0.9967</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B004N5J568</td>\n",
       "      <td>[{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4836</td>\n",
       "      <td>182.0</td>\n",
       "      <td>Scharffen Berger Natural Unsweetened Cocoa Pow...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>0.9178</td>\n",
       "      <td>0.438763</td>\n",
       "      <td>0.9544</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B004N5J568</td>\n",
       "      <td>[{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4836</td>\n",
       "      <td>182.0</td>\n",
       "      <td>Scharffen Berger Natural Unsweetened Cocoa Pow...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0516</td>\n",
       "      <td>0.8112</td>\n",
       "      <td>0.390139</td>\n",
       "      <td>0.9983</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B004N5J568</td>\n",
       "      <td>[{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4836</td>\n",
       "      <td>182.0</td>\n",
       "      <td>Scharffen Berger Natural Unsweetened Cocoa Pow...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8439</td>\n",
       "      <td>0.9679</td>\n",
       "      <td>0.359494</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B004N5J568</td>\n",
       "      <td>[{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4836</td>\n",
       "      <td>182.0</td>\n",
       "      <td>Scharffen Berger Natural Unsweetened Cocoa Pow...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.351100</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B004N5J568</td>\n",
       "      <td>[{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4836</td>\n",
       "      <td>182.0</td>\n",
       "      <td>Scharffen Berger Natural Unsweetened Cocoa Pow...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.8952</td>\n",
       "      <td>0.841048</td>\n",
       "      <td>0.9958</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B004N5J568</td>\n",
       "      <td>[{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4836</td>\n",
       "      <td>182.0</td>\n",
       "      <td>Scharffen Berger Natural Unsweetened Cocoa Pow...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9509</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.605092</td>\n",
       "      <td>0.2773</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B07KK66VKC</td>\n",
       "      <td>[{'5 star': '88%'}, {'4 star': '8%'}, {'3 star...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6470</td>\n",
       "      <td>5066.0</td>\n",
       "      <td>Swiss Miss Cocoa Milk Chocolate Canister, 45.6...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>5337</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.8950</td>\n",
       "      <td>0.0467</td>\n",
       "      <td>0.642514</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B07KK66VKC</td>\n",
       "      <td>[{'5 star': '88%'}, {'4 star': '8%'}, {'3 star...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6470</td>\n",
       "      <td>5066.0</td>\n",
       "      <td>Swiss Miss Cocoa Milk Chocolate Canister, 45.6...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>5337</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5640</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.760769</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B07KK66VKC</td>\n",
       "      <td>[{'5 star': '88%'}, {'4 star': '8%'}, {'3 star...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6470</td>\n",
       "      <td>5066.0</td>\n",
       "      <td>Swiss Miss Cocoa Milk Chocolate Canister, 45.6...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>5337</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1672</td>\n",
       "      <td>0.0960</td>\n",
       "      <td>0.462988</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B07KK66VKC</td>\n",
       "      <td>[{'5 star': '88%'}, {'4 star': '8%'}, {'3 star...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6470</td>\n",
       "      <td>5066.0</td>\n",
       "      <td>Swiss Miss Cocoa Milk Chocolate Canister, 45.6...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>5337</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8389</td>\n",
       "      <td>0.1930</td>\n",
       "      <td>0.777485</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>B07KK66VKC</td>\n",
       "      <td>[{'5 star': '88%'}, {'4 star': '8%'}, {'3 star...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6470</td>\n",
       "      <td>5066.0</td>\n",
       "      <td>Swiss Miss Cocoa Milk Chocolate Canister, 45.6...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>5337</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9460</td>\n",
       "      <td>0.2627</td>\n",
       "      <td>0.610613</td>\n",
       "      <td>0.3485</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>B07KK66VKC</td>\n",
       "      <td>[{'5 star': '88%'}, {'4 star': '8%'}, {'3 star...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6470</td>\n",
       "      <td>5066.0</td>\n",
       "      <td>Swiss Miss Cocoa Milk Chocolate Canister, 45.6...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>5337</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1027</td>\n",
       "      <td>0.0398</td>\n",
       "      <td>0.547240</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>B07KK66VKC</td>\n",
       "      <td>[{'5 star': '88%'}, {'4 star': '8%'}, {'3 star...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6470</td>\n",
       "      <td>5066.0</td>\n",
       "      <td>Swiss Miss Cocoa Milk Chocolate Canister, 45.6...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>5337</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.3064</td>\n",
       "      <td>0.6849</td>\n",
       "      <td>0.582769</td>\n",
       "      <td>0.0930</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>B07KK66VKC</td>\n",
       "      <td>[{'5 star': '88%'}, {'4 star': '8%'}, {'3 star...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6470</td>\n",
       "      <td>5066.0</td>\n",
       "      <td>Swiss Miss Cocoa Milk Chocolate Canister, 45.6...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>5337</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1761</td>\n",
       "      <td>0.0992</td>\n",
       "      <td>0.809669</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>B07KK66VKC</td>\n",
       "      <td>[{'5 star': '88%'}, {'4 star': '8%'}, {'3 star...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6470</td>\n",
       "      <td>5066.0</td>\n",
       "      <td>Swiss Miss Cocoa Milk Chocolate Canister, 45.6...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>5337</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9265</td>\n",
       "      <td>0.9929</td>\n",
       "      <td>0.373454</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>B08PDRLN57</td>\n",
       "      <td>[{'5 star': '84%'}, {'4 star': '9%'}, {'3 star...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4381</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Botanica Origins Premium Organic Cacao Powder,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9737</td>\n",
       "      <td>0.8660</td>\n",
       "      <td>0.774532</td>\n",
       "      <td>0.9982</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>B08PDRLN57</td>\n",
       "      <td>[{'5 star': '84%'}, {'4 star': '9%'}, {'3 star...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4381</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Botanica Origins Premium Organic Cacao Powder,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9468</td>\n",
       "      <td>0.9884</td>\n",
       "      <td>0.537792</td>\n",
       "      <td>0.9982</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>B08PDRLN57</td>\n",
       "      <td>[{'5 star': '84%'}, {'4 star': '9%'}, {'3 star...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4381</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Botanica Origins Premium Organic Cacao Powder,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9602</td>\n",
       "      <td>0.9436</td>\n",
       "      <td>0.562326</td>\n",
       "      <td>0.9943</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>B08PDRLN57</td>\n",
       "      <td>[{'5 star': '84%'}, {'4 star': '9%'}, {'3 star...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4381</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Botanica Origins Premium Organic Cacao Powder,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8979</td>\n",
       "      <td>0.9880</td>\n",
       "      <td>0.355557</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>B08PDRLN57</td>\n",
       "      <td>[{'5 star': '84%'}, {'4 star': '9%'}, {'3 star...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4381</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Botanica Origins Premium Organic Cacao Powder,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>0.9894</td>\n",
       "      <td>0.553055</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>B08PDRLN57</td>\n",
       "      <td>[{'5 star': '84%'}, {'4 star': '9%'}, {'3 star...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4381</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Botanica Origins Premium Organic Cacao Powder,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9151</td>\n",
       "      <td>0.9741</td>\n",
       "      <td>0.459127</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>B08PDRLN57</td>\n",
       "      <td>[{'5 star': '84%'}, {'4 star': '9%'}, {'3 star...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4381</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Botanica Origins Premium Organic Cacao Powder,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.417386</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>B08PDRLN57</td>\n",
       "      <td>[{'5 star': '84%'}, {'4 star': '9%'}, {'3 star...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4381</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Botanica Origins Premium Organic Cacao Powder,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9811</td>\n",
       "      <td>0.9873</td>\n",
       "      <td>0.435427</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>B08CTJSF76</td>\n",
       "      <td>[{'5 star': '86%'}, {'4 star': '9%'}, {'3 star...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1069</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Cocoa Butter Chips - Organic - Unrefined - 8 l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8122</td>\n",
       "      <td>0.9837</td>\n",
       "      <td>0.401868</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>B08CTJSF76</td>\n",
       "      <td>[{'5 star': '86%'}, {'4 star': '9%'}, {'3 star...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1069</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Cocoa Butter Chips - Organic - Unrefined - 8 l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9330</td>\n",
       "      <td>0.9901</td>\n",
       "      <td>0.347432</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>B08CTJSF76</td>\n",
       "      <td>[{'5 star': '86%'}, {'4 star': '9%'}, {'3 star...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1069</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Cocoa Butter Chips - Organic - Unrefined - 8 l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>0.8847</td>\n",
       "      <td>0.267682</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>B08CTJSF76</td>\n",
       "      <td>[{'5 star': '86%'}, {'4 star': '9%'}, {'3 star...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1069</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Cocoa Butter Chips - Organic - Unrefined - 8 l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8396</td>\n",
       "      <td>0.9798</td>\n",
       "      <td>0.486168</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>B08CTJSF76</td>\n",
       "      <td>[{'5 star': '86%'}, {'4 star': '9%'}, {'3 star...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1069</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Cocoa Butter Chips - Organic - Unrefined - 8 l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8126</td>\n",
       "      <td>0.9854</td>\n",
       "      <td>0.271059</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>B08X4ZRP3P</td>\n",
       "      <td>[{'5 star': '83%'}, {'4 star': '8%'}, {'3 star...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1802</td>\n",
       "      <td>157.0</td>\n",
       "      <td>Cordillera | 100% Natural Cacao Powder 10-12% ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9303</td>\n",
       "      <td>0.442679</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>B08X4ZRP3P</td>\n",
       "      <td>[{'5 star': '83%'}, {'4 star': '8%'}, {'3 star...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1802</td>\n",
       "      <td>157.0</td>\n",
       "      <td>Cordillera | 100% Natural Cacao Powder 10-12% ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.3318</td>\n",
       "      <td>0.1825</td>\n",
       "      <td>0.751185</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>B08X4ZRP3P</td>\n",
       "      <td>[{'5 star': '83%'}, {'4 star': '8%'}, {'3 star...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1802</td>\n",
       "      <td>157.0</td>\n",
       "      <td>Cordillera | 100% Natural Cacao Powder 10-12% ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.7003</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.427773</td>\n",
       "      <td>0.9553</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>B08X4ZRP3P</td>\n",
       "      <td>[{'5 star': '83%'}, {'4 star': '8%'}, {'3 star...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1802</td>\n",
       "      <td>157.0</td>\n",
       "      <td>Cordillera | 100% Natural Cacao Powder 10-12% ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.1365</td>\n",
       "      <td>0.440412</td>\n",
       "      <td>0.2634</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>B08X4ZRP3P</td>\n",
       "      <td>[{'5 star': '83%'}, {'4 star': '8%'}, {'3 star...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1802</td>\n",
       "      <td>157.0</td>\n",
       "      <td>Cordillera | 100% Natural Cacao Powder 10-12% ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9117</td>\n",
       "      <td>0.9837</td>\n",
       "      <td>0.402493</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>B08X4ZRP3P</td>\n",
       "      <td>[{'5 star': '83%'}, {'4 star': '8%'}, {'3 star...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1802</td>\n",
       "      <td>157.0</td>\n",
       "      <td>Cordillera | 100% Natural Cacao Powder 10-12% ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.702761</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>B08X4ZRP3P</td>\n",
       "      <td>[{'5 star': '83%'}, {'4 star': '8%'}, {'3 star...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1802</td>\n",
       "      <td>157.0</td>\n",
       "      <td>Cordillera | 100% Natural Cacao Powder 10-12% ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>0.8313</td>\n",
       "      <td>0.296808</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>B08X4ZRP3P</td>\n",
       "      <td>[{'5 star': '83%'}, {'4 star': '8%'}, {'3 star...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1802</td>\n",
       "      <td>157.0</td>\n",
       "      <td>Cordillera | 100% Natural Cacao Powder 10-12% ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.3939</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.891789</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>B078VWBKDW</td>\n",
       "      <td>[{'5 star': '84%'}, {'4 star': '11%'}, {'3 sta...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4128</td>\n",
       "      <td>943.0</td>\n",
       "      <td>Eat Well Premium Foods - Cacao Powder 32 oz (2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>1205</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9558</td>\n",
       "      <td>0.600049</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>B078VWBKDW</td>\n",
       "      <td>[{'5 star': '84%'}, {'4 star': '11%'}, {'3 sta...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4128</td>\n",
       "      <td>943.0</td>\n",
       "      <td>Eat Well Premium Foods - Cacao Powder 32 oz (2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>1205</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8748</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.678371</td>\n",
       "      <td>0.9669</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>B078VWBKDW</td>\n",
       "      <td>[{'5 star': '84%'}, {'4 star': '11%'}, {'3 sta...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4128</td>\n",
       "      <td>943.0</td>\n",
       "      <td>Eat Well Premium Foods - Cacao Powder 32 oz (2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>1205</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.7901</td>\n",
       "      <td>0.9013</td>\n",
       "      <td>0.708846</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>B078VWBKDW</td>\n",
       "      <td>[{'5 star': '84%'}, {'4 star': '11%'}, {'3 sta...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4128</td>\n",
       "      <td>943.0</td>\n",
       "      <td>Eat Well Premium Foods - Cacao Powder 32 oz (2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>1205</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9752</td>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.483165</td>\n",
       "      <td>0.9983</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>B078VWBKDW</td>\n",
       "      <td>[{'5 star': '84%'}, {'4 star': '11%'}, {'3 sta...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4128</td>\n",
       "      <td>943.0</td>\n",
       "      <td>Eat Well Premium Foods - Cacao Powder 32 oz (2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>1205</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.1280</td>\n",
       "      <td>0.7660</td>\n",
       "      <td>0.694246</td>\n",
       "      <td>0.9196</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>B078VWBKDW</td>\n",
       "      <td>[{'5 star': '84%'}, {'4 star': '11%'}, {'3 sta...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4128</td>\n",
       "      <td>943.0</td>\n",
       "      <td>Eat Well Premium Foods - Cacao Powder 32 oz (2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>1205</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.0569</td>\n",
       "      <td>0.881733</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>B078VWBKDW</td>\n",
       "      <td>[{'5 star': '84%'}, {'4 star': '11%'}, {'3 sta...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4128</td>\n",
       "      <td>943.0</td>\n",
       "      <td>Eat Well Premium Foods - Cacao Powder 32 oz (2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>1205</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.1992</td>\n",
       "      <td>0.824323</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>B078VWBKDW</td>\n",
       "      <td>[{'5 star': '84%'}, {'4 star': '11%'}, {'3 sta...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4128</td>\n",
       "      <td>943.0</td>\n",
       "      <td>Eat Well Premium Foods - Cacao Powder 32 oz (2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>1205</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.4927</td>\n",
       "      <td>0.9697</td>\n",
       "      <td>0.578581</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>B001G604YY</td>\n",
       "      <td>[{'5 star': '82%'}, {'4 star': '9%'}, {'3 star...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5912</td>\n",
       "      <td>3570.0</td>\n",
       "      <td>Ghirardelli Chocolate Sweet Ground White Choco...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>3760</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8689</td>\n",
       "      <td>0.4111</td>\n",
       "      <td>0.623399</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>B001G604YY</td>\n",
       "      <td>[{'5 star': '82%'}, {'4 star': '9%'}, {'3 star...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5912</td>\n",
       "      <td>3570.0</td>\n",
       "      <td>Ghirardelli Chocolate Sweet Ground White Choco...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>3760</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.7757</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.794089</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>B001G604YY</td>\n",
       "      <td>[{'5 star': '82%'}, {'4 star': '9%'}, {'3 star...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5912</td>\n",
       "      <td>3570.0</td>\n",
       "      <td>Ghirardelli Chocolate Sweet Ground White Choco...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>3760</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8226</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.855278</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>B001G604YY</td>\n",
       "      <td>[{'5 star': '82%'}, {'4 star': '9%'}, {'3 star...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5912</td>\n",
       "      <td>3570.0</td>\n",
       "      <td>Ghirardelli Chocolate Sweet Ground White Choco...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>3760</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7355</td>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.794764</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SourceUserId                                  reviews_by_rating  \\\n",
       "0    B004N5J568  [{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...   \n",
       "1    B004N5J568  [{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...   \n",
       "2    B004N5J568  [{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...   \n",
       "3    B004N5J568  [{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...   \n",
       "4    B004N5J568  [{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...   \n",
       "5    B004N5J568  [{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...   \n",
       "6    B004N5J568  [{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...   \n",
       "7    B004N5J568  [{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...   \n",
       "8    B07KK66VKC  [{'5 star': '88%'}, {'4 star': '8%'}, {'3 star...   \n",
       "9    B07KK66VKC  [{'5 star': '88%'}, {'4 star': '8%'}, {'3 star...   \n",
       "10   B07KK66VKC  [{'5 star': '88%'}, {'4 star': '8%'}, {'3 star...   \n",
       "11   B07KK66VKC  [{'5 star': '88%'}, {'4 star': '8%'}, {'3 star...   \n",
       "12   B07KK66VKC  [{'5 star': '88%'}, {'4 star': '8%'}, {'3 star...   \n",
       "13   B07KK66VKC  [{'5 star': '88%'}, {'4 star': '8%'}, {'3 star...   \n",
       "14   B07KK66VKC  [{'5 star': '88%'}, {'4 star': '8%'}, {'3 star...   \n",
       "15   B07KK66VKC  [{'5 star': '88%'}, {'4 star': '8%'}, {'3 star...   \n",
       "16   B07KK66VKC  [{'5 star': '88%'}, {'4 star': '8%'}, {'3 star...   \n",
       "17   B08PDRLN57  [{'5 star': '84%'}, {'4 star': '9%'}, {'3 star...   \n",
       "18   B08PDRLN57  [{'5 star': '84%'}, {'4 star': '9%'}, {'3 star...   \n",
       "19   B08PDRLN57  [{'5 star': '84%'}, {'4 star': '9%'}, {'3 star...   \n",
       "20   B08PDRLN57  [{'5 star': '84%'}, {'4 star': '9%'}, {'3 star...   \n",
       "21   B08PDRLN57  [{'5 star': '84%'}, {'4 star': '9%'}, {'3 star...   \n",
       "22   B08PDRLN57  [{'5 star': '84%'}, {'4 star': '9%'}, {'3 star...   \n",
       "23   B08PDRLN57  [{'5 star': '84%'}, {'4 star': '9%'}, {'3 star...   \n",
       "24   B08PDRLN57  [{'5 star': '84%'}, {'4 star': '9%'}, {'3 star...   \n",
       "25   B08CTJSF76  [{'5 star': '86%'}, {'4 star': '9%'}, {'3 star...   \n",
       "26   B08CTJSF76  [{'5 star': '86%'}, {'4 star': '9%'}, {'3 star...   \n",
       "27   B08CTJSF76  [{'5 star': '86%'}, {'4 star': '9%'}, {'3 star...   \n",
       "28   B08CTJSF76  [{'5 star': '86%'}, {'4 star': '9%'}, {'3 star...   \n",
       "29   B08CTJSF76  [{'5 star': '86%'}, {'4 star': '9%'}, {'3 star...   \n",
       "30   B08X4ZRP3P  [{'5 star': '83%'}, {'4 star': '8%'}, {'3 star...   \n",
       "31   B08X4ZRP3P  [{'5 star': '83%'}, {'4 star': '8%'}, {'3 star...   \n",
       "32   B08X4ZRP3P  [{'5 star': '83%'}, {'4 star': '8%'}, {'3 star...   \n",
       "33   B08X4ZRP3P  [{'5 star': '83%'}, {'4 star': '8%'}, {'3 star...   \n",
       "34   B08X4ZRP3P  [{'5 star': '83%'}, {'4 star': '8%'}, {'3 star...   \n",
       "35   B08X4ZRP3P  [{'5 star': '83%'}, {'4 star': '8%'}, {'3 star...   \n",
       "36   B08X4ZRP3P  [{'5 star': '83%'}, {'4 star': '8%'}, {'3 star...   \n",
       "37   B08X4ZRP3P  [{'5 star': '83%'}, {'4 star': '8%'}, {'3 star...   \n",
       "38   B078VWBKDW  [{'5 star': '84%'}, {'4 star': '11%'}, {'3 sta...   \n",
       "39   B078VWBKDW  [{'5 star': '84%'}, {'4 star': '11%'}, {'3 sta...   \n",
       "40   B078VWBKDW  [{'5 star': '84%'}, {'4 star': '11%'}, {'3 sta...   \n",
       "41   B078VWBKDW  [{'5 star': '84%'}, {'4 star': '11%'}, {'3 sta...   \n",
       "42   B078VWBKDW  [{'5 star': '84%'}, {'4 star': '11%'}, {'3 sta...   \n",
       "43   B078VWBKDW  [{'5 star': '84%'}, {'4 star': '11%'}, {'3 sta...   \n",
       "44   B078VWBKDW  [{'5 star': '84%'}, {'4 star': '11%'}, {'3 sta...   \n",
       "45   B078VWBKDW  [{'5 star': '84%'}, {'4 star': '11%'}, {'3 sta...   \n",
       "46   B001G604YY  [{'5 star': '82%'}, {'4 star': '9%'}, {'3 star...   \n",
       "47   B001G604YY  [{'5 star': '82%'}, {'4 star': '9%'}, {'3 star...   \n",
       "48   B001G604YY  [{'5 star': '82%'}, {'4 star': '9%'}, {'3 star...   \n",
       "49   B001G604YY  [{'5 star': '82%'}, {'4 star': '9%'}, {'3 star...   \n",
       "\n",
       "    average_rating  number_of_reviews  number_of_rating  \\\n",
       "0              4.9               4836             182.0   \n",
       "1              4.9               4836             182.0   \n",
       "2              4.9               4836             182.0   \n",
       "3              4.9               4836             182.0   \n",
       "4              4.9               4836             182.0   \n",
       "5              4.9               4836             182.0   \n",
       "6              4.9               4836             182.0   \n",
       "7              4.9               4836             182.0   \n",
       "8              4.8               6470            5066.0   \n",
       "9              4.8               6470            5066.0   \n",
       "10             4.8               6470            5066.0   \n",
       "11             4.8               6470            5066.0   \n",
       "12             4.8               6470            5066.0   \n",
       "13             4.8               6470            5066.0   \n",
       "14             4.8               6470            5066.0   \n",
       "15             4.8               6470            5066.0   \n",
       "16             4.8               6470            5066.0   \n",
       "17             4.8               4381              41.0   \n",
       "18             4.8               4381              41.0   \n",
       "19             4.8               4381              41.0   \n",
       "20             4.8               4381              41.0   \n",
       "21             4.8               4381              41.0   \n",
       "22             4.8               4381              41.0   \n",
       "23             4.8               4381              41.0   \n",
       "24             4.8               4381              41.0   \n",
       "25             4.8               1069              30.0   \n",
       "26             4.8               1069              30.0   \n",
       "27             4.8               1069              30.0   \n",
       "28             4.8               1069              30.0   \n",
       "29             4.8               1069              30.0   \n",
       "30             4.7               1802             157.0   \n",
       "31             4.7               1802             157.0   \n",
       "32             4.7               1802             157.0   \n",
       "33             4.7               1802             157.0   \n",
       "34             4.7               1802             157.0   \n",
       "35             4.7               1802             157.0   \n",
       "36             4.7               1802             157.0   \n",
       "37             4.7               1802             157.0   \n",
       "38             4.7               4128             943.0   \n",
       "39             4.7               4128             943.0   \n",
       "40             4.7               4128             943.0   \n",
       "41             4.7               4128             943.0   \n",
       "42             4.7               4128             943.0   \n",
       "43             4.7               4128             943.0   \n",
       "44             4.7               4128             943.0   \n",
       "45             4.7               4128             943.0   \n",
       "46             4.7               5912            3570.0   \n",
       "47             4.7               5912            3570.0   \n",
       "48             4.7               5912            3570.0   \n",
       "49             4.7               5912            3570.0   \n",
       "\n",
       "                                       MentionEnglish  Sentiment KeyTerms  \\\n",
       "0   Scharffen Berger Natural Unsweetened Cocoa Pow...        NaN    cocoa   \n",
       "1   Scharffen Berger Natural Unsweetened Cocoa Pow...        NaN    cocoa   \n",
       "2   Scharffen Berger Natural Unsweetened Cocoa Pow...        NaN    cocoa   \n",
       "3   Scharffen Berger Natural Unsweetened Cocoa Pow...        NaN    cocoa   \n",
       "4   Scharffen Berger Natural Unsweetened Cocoa Pow...        NaN    cocoa   \n",
       "5   Scharffen Berger Natural Unsweetened Cocoa Pow...        NaN    cocoa   \n",
       "6   Scharffen Berger Natural Unsweetened Cocoa Pow...        NaN    cocoa   \n",
       "7   Scharffen Berger Natural Unsweetened Cocoa Pow...        NaN    cocoa   \n",
       "8   Swiss Miss Cocoa Milk Chocolate Canister, 45.6...        NaN    cocoa   \n",
       "9   Swiss Miss Cocoa Milk Chocolate Canister, 45.6...        NaN    cocoa   \n",
       "10  Swiss Miss Cocoa Milk Chocolate Canister, 45.6...        NaN    cocoa   \n",
       "11  Swiss Miss Cocoa Milk Chocolate Canister, 45.6...        NaN    cocoa   \n",
       "12  Swiss Miss Cocoa Milk Chocolate Canister, 45.6...        NaN    cocoa   \n",
       "13  Swiss Miss Cocoa Milk Chocolate Canister, 45.6...        NaN    cocoa   \n",
       "14  Swiss Miss Cocoa Milk Chocolate Canister, 45.6...        NaN    cocoa   \n",
       "15  Swiss Miss Cocoa Milk Chocolate Canister, 45.6...        NaN    cocoa   \n",
       "16  Swiss Miss Cocoa Milk Chocolate Canister, 45.6...        NaN    cocoa   \n",
       "17  Botanica Origins Premium Organic Cacao Powder,...        NaN    cocoa   \n",
       "18  Botanica Origins Premium Organic Cacao Powder,...        NaN    cocoa   \n",
       "19  Botanica Origins Premium Organic Cacao Powder,...        NaN    cocoa   \n",
       "20  Botanica Origins Premium Organic Cacao Powder,...        NaN    cocoa   \n",
       "21  Botanica Origins Premium Organic Cacao Powder,...        NaN    cocoa   \n",
       "22  Botanica Origins Premium Organic Cacao Powder,...        NaN    cocoa   \n",
       "23  Botanica Origins Premium Organic Cacao Powder,...        NaN    cocoa   \n",
       "24  Botanica Origins Premium Organic Cacao Powder,...        NaN    cocoa   \n",
       "25  Cocoa Butter Chips - Organic - Unrefined - 8 l...        NaN    cocoa   \n",
       "26  Cocoa Butter Chips - Organic - Unrefined - 8 l...        NaN    cocoa   \n",
       "27  Cocoa Butter Chips - Organic - Unrefined - 8 l...        NaN    cocoa   \n",
       "28  Cocoa Butter Chips - Organic - Unrefined - 8 l...        NaN    cocoa   \n",
       "29  Cocoa Butter Chips - Organic - Unrefined - 8 l...        NaN    cocoa   \n",
       "30  Cordillera | 100% Natural Cacao Powder 10-12% ...        NaN    cocoa   \n",
       "31  Cordillera | 100% Natural Cacao Powder 10-12% ...        NaN    cocoa   \n",
       "32  Cordillera | 100% Natural Cacao Powder 10-12% ...        NaN    cocoa   \n",
       "33  Cordillera | 100% Natural Cacao Powder 10-12% ...        NaN    cocoa   \n",
       "34  Cordillera | 100% Natural Cacao Powder 10-12% ...        NaN    cocoa   \n",
       "35  Cordillera | 100% Natural Cacao Powder 10-12% ...        NaN    cocoa   \n",
       "36  Cordillera | 100% Natural Cacao Powder 10-12% ...        NaN    cocoa   \n",
       "37  Cordillera | 100% Natural Cacao Powder 10-12% ...        NaN    cocoa   \n",
       "38  Eat Well Premium Foods - Cacao Powder 32 oz (2...        NaN    cocoa   \n",
       "39  Eat Well Premium Foods - Cacao Powder 32 oz (2...        NaN    cocoa   \n",
       "40  Eat Well Premium Foods - Cacao Powder 32 oz (2...        NaN    cocoa   \n",
       "41  Eat Well Premium Foods - Cacao Powder 32 oz (2...        NaN    cocoa   \n",
       "42  Eat Well Premium Foods - Cacao Powder 32 oz (2...        NaN    cocoa   \n",
       "43  Eat Well Premium Foods - Cacao Powder 32 oz (2...        NaN    cocoa   \n",
       "44  Eat Well Premium Foods - Cacao Powder 32 oz (2...        NaN    cocoa   \n",
       "45  Eat Well Premium Foods - Cacao Powder 32 oz (2...        NaN    cocoa   \n",
       "46  Ghirardelli Chocolate Sweet Ground White Choco...        NaN    cocoa   \n",
       "47  Ghirardelli Chocolate Sweet Ground White Choco...        NaN    cocoa   \n",
       "48  Ghirardelli Chocolate Sweet Ground White Choco...        NaN    cocoa   \n",
       "49  Ghirardelli Chocolate Sweet Ground White Choco...        NaN    cocoa   \n",
       "\n",
       "    Quantity  Growth  ... reaction  label  vader_scores  roberta_scores  \\\n",
       "0        255       0  ...        8    5.0        0.9190          0.9526   \n",
       "1        255       0  ...       17    5.0        0.9767          0.7285   \n",
       "2        255       0  ...        4    5.0        0.3612          0.9178   \n",
       "3        255       0  ...        2    5.0        0.0516          0.8112   \n",
       "4        255       0  ...        1    5.0        0.8439          0.9679   \n",
       "5        255       0  ...        2    5.0        0.5719          0.9550   \n",
       "6        255       0  ...       31    5.0        0.9841          0.8952   \n",
       "7        255       0  ...        0    2.0        0.9509          0.2173   \n",
       "8       5337       0  ...       70    3.0       -0.8950          0.0467   \n",
       "9       5337       0  ...       44    2.0        0.5640          0.0069   \n",
       "10      5337       0  ...       39    1.0        0.1672          0.0960   \n",
       "11      5337       0  ...       42    1.0        0.8389          0.1930   \n",
       "12      5337       0  ...       27    2.0        0.9460          0.2627   \n",
       "13      5337       0  ...       25    1.0        0.1027          0.0398   \n",
       "14      5337       0  ...       11    5.0        0.3064          0.6849   \n",
       "15      5337       0  ...        4    2.0        0.1761          0.0992   \n",
       "16      5337       0  ...        0    5.0        0.9265          0.9929   \n",
       "17        68       0  ...        6    5.0        0.9737          0.8660   \n",
       "18        68       0  ...        7    5.0        0.9468          0.9884   \n",
       "19        68       0  ...        2    5.0        0.9602          0.9436   \n",
       "20        68       0  ...        2    5.0        0.8979          0.9880   \n",
       "21        68       0  ...        2    5.0        0.9905          0.9894   \n",
       "22        68       0  ...        0    5.0        0.9151          0.9741   \n",
       "23        68       0  ...        0    5.0        0.9758          0.9815   \n",
       "24        68       0  ...        0    5.0        0.9811          0.9873   \n",
       "25        40       0  ...        3    5.0        0.8122          0.9837   \n",
       "26        40       0  ...        0    5.0        0.9330          0.9901   \n",
       "27        40       0  ...        0    5.0        0.6486          0.8847   \n",
       "28        40       0  ...        0    5.0        0.8396          0.9798   \n",
       "29        40       0  ...        2    5.0        0.8126          0.9854   \n",
       "30       211       0  ...       16    5.0        0.0000          0.9303   \n",
       "31       211       0  ...       10    2.0       -0.3318          0.1825   \n",
       "32       211       0  ...        5    5.0        0.7003          0.9730   \n",
       "33       211       0  ...        4    2.0        0.5267          0.1365   \n",
       "34       211       0  ...        5    4.0        0.9117          0.9837   \n",
       "35       211       0  ...        3    3.0        0.0000          0.0119   \n",
       "36       211       0  ...        3    5.0        0.5719          0.8313   \n",
       "37       211       0  ...        0    3.0       -0.3939          0.0151   \n",
       "38      1205       0  ...       48    5.0        0.9907          0.9558   \n",
       "39      1205       0  ...       34    5.0        0.8748          0.9673   \n",
       "40      1205       0  ...       30    5.0        0.7901          0.9013   \n",
       "41      1205       0  ...       30    5.0        0.9752          0.9877   \n",
       "42      1205       0  ...       32    5.0       -0.1280          0.7660   \n",
       "43      1205       0  ...        6    1.0        0.4767          0.0569   \n",
       "44      1205       0  ...        1    5.0        0.5255          0.1992   \n",
       "45      1205       0  ...       73    5.0        0.4927          0.9697   \n",
       "46      3760       0  ...       60    1.0        0.8689          0.4111   \n",
       "47      3760       0  ...       45    1.0       -0.7757          0.0087   \n",
       "48      3760       0  ...       15    1.0        0.8226          0.0043   \n",
       "49      3760       0  ...       40    1.0        0.7355          0.0442   \n",
       "\n",
       "    microsoft_scores  distilbert_scores vader_label roberta_label  \\\n",
       "0           0.691417             0.9989           5             5   \n",
       "1           0.643807             0.9967           5             4   \n",
       "2           0.438763             0.9544           4             5   \n",
       "3           0.390139             0.9983           3             5   \n",
       "4           0.359494             0.9994           5             5   \n",
       "5           0.351100             0.9996           4             5   \n",
       "6           0.841048             0.9958           5             5   \n",
       "7           0.605092             0.2773           5             2   \n",
       "8           0.642514             0.0006           1             1   \n",
       "9           0.760769             0.0022           4             1   \n",
       "10          0.462988             0.0092           3             1   \n",
       "11          0.777485             0.0005           5             1   \n",
       "12          0.610613             0.3485           5             2   \n",
       "13          0.547240             0.0007           3             1   \n",
       "14          0.582769             0.0930           4             4   \n",
       "15          0.809669             0.0042           3             1   \n",
       "16          0.373454             0.9999           5             5   \n",
       "17          0.774532             0.9982           5             5   \n",
       "18          0.537792             0.9982           5             5   \n",
       "19          0.562326             0.9943           5             5   \n",
       "20          0.355557             0.9994           5             5   \n",
       "21          0.553055             0.9996           5             5   \n",
       "22          0.459127             0.9998           5             5   \n",
       "23          0.417386             0.9997           5             5   \n",
       "24          0.435427             0.9998           5             5   \n",
       "25          0.401868             0.9998           5             5   \n",
       "26          0.347432             0.9998           5             5   \n",
       "27          0.267682             0.9998           5             5   \n",
       "28          0.486168             0.9997           5             5   \n",
       "29          0.271059             0.9997           5             5   \n",
       "30          0.442679             0.9997           5             5   \n",
       "31          0.751185             0.0101           2             1   \n",
       "32          0.427773             0.9553           5             5   \n",
       "33          0.440412             0.2634           4             1   \n",
       "34          0.402493             0.9999           5             5   \n",
       "35          0.702761             0.0003           5             1   \n",
       "36          0.296808             0.9998           4             5   \n",
       "37          0.891789             0.0011           2             1   \n",
       "38          0.600049             0.9988           5             5   \n",
       "39          0.678371             0.9669           5             5   \n",
       "40          0.708846             0.0350           5             5   \n",
       "41          0.483165             0.9983           5             5   \n",
       "42          0.694246             0.9196           3             4   \n",
       "43          0.881733             0.0164           4             1   \n",
       "44          0.824323             0.0082           4             1   \n",
       "45          0.578581             0.9998           4             5   \n",
       "46          0.623399             0.0211           5             3   \n",
       "47          0.794089             0.0006           1             1   \n",
       "48          0.855278             0.0342           5             1   \n",
       "49          0.794764             0.0044           5             1   \n",
       "\n",
       "    microsoft_label  distilbert_label  \n",
       "0                 4                 5  \n",
       "1                 4                 5  \n",
       "2                 3                 5  \n",
       "3                 2                 5  \n",
       "4                 2                 5  \n",
       "5                 2                 5  \n",
       "6                 5                 5  \n",
       "7                 4                 2  \n",
       "8                 4                 1  \n",
       "9                 4                 1  \n",
       "10                3                 1  \n",
       "11                4                 1  \n",
       "12                4                 2  \n",
       "13                3                 1  \n",
       "14                3                 1  \n",
       "15                5                 1  \n",
       "16                2                 5  \n",
       "17                4                 5  \n",
       "18                3                 5  \n",
       "19                3                 5  \n",
       "20                2                 5  \n",
       "21                3                 5  \n",
       "22                3                 5  \n",
       "23                3                 5  \n",
       "24                3                 5  \n",
       "25                3                 5  \n",
       "26                2                 5  \n",
       "27                2                 5  \n",
       "28                3                 5  \n",
       "29                2                 5  \n",
       "30                3                 5  \n",
       "31                4                 1  \n",
       "32                3                 5  \n",
       "33                3                 2  \n",
       "34                3                 5  \n",
       "35                4                 1  \n",
       "36                2                 5  \n",
       "37                5                 1  \n",
       "38                4                 5  \n",
       "39                4                 5  \n",
       "40                4                 1  \n",
       "41                3                 5  \n",
       "42                4                 5  \n",
       "43                5                 1  \n",
       "44                5                 1  \n",
       "45                3                 5  \n",
       "46                4                 1  \n",
       "47                4                 1  \n",
       "48                5                 1  \n",
       "49                4                 1  \n",
       "\n",
       "[50 rows x 28 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_accuracy(df, scores, target):\n",
    "    non_zero_df = df[df[scores] != 0]\n",
    "    total_len= len(non_zero_df)\n",
    "    is_equal_sum = sum([a==b for a, b in zip(df[\"label\"], df[target])])  \n",
    "    return f\"{round((is_equal_sum/total_len)*100, 2)}%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'61.49%'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_accuracy(reviews_df, \"vader_scores\", \"vader_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'62.42%'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_accuracy(reviews_df, \"roberta_scores\", \"roberta_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'68.14%'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_accuracy(reviews_df, \"distilbert_scores\", \"distilbert_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8.46%'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_accuracy(reviews_df, \"microsoft_scores\", \"microsoft_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.to_csv(\"processed_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report on Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8486486486486486"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "\n",
    "accuracy_score(reviews_df['label'], reviews_df['Sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that VADER correctly identified an Amazon review as \"positive\" or \"negative\" roughly 71% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.59      0.45      0.51       163\n",
      "         pos       0.89      0.93      0.91       762\n",
      "\n",
      "    accuracy                           0.85       925\n",
      "   macro avg       0.74      0.69      0.71       925\n",
      "weighted avg       0.84      0.85      0.84       925\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(reviews_df['label'], reviews_df['Sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 73  90]\n",
      " [ 50 712]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(reviews_df['label'], reviews_df['Sentiment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also make a wordcloud visualization of the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "sentiment = 'pos'\n",
    "\n",
    "# Combine all reviews for the desired sentiment\n",
    "combined_text = \" \".join([review for review in reviews_df[reviews_df['label'] == sentiment][\"comments\"]])\n",
    "\n",
    "# Initialize wordcloud object\n",
    "wc = WordCloud(background_color='white', max_words=50,\n",
    "        # update stopwords to include common words like film and movie\n",
    "        stopwords = STOPWORDS.update(['will','coffe','think']))\n",
    "\n",
    "# Generate and plot wordcloud\n",
    "plt.imshow(wc.generate(combined_text))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELING THE REVIEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer(s):\n",
    "    s = s.lower()  # downcase\n",
    "    s = re.sub(r\"[^a-zA-Z0-9]\", ' ', s.lower())\n",
    "    tokens = nltk.tokenize.word_tokenize(s)  # split string into words (tokens)\n",
    "    # remove short words, they're probably not useful\n",
    "    tokens = [t for t in tokens if len(t) > 2]\n",
    "    # put words into base form\n",
    "    tokens = [wordnet_lemmatizer.lemmatize(t) for t in tokens]\n",
    "    tokens = [t for t in tokens if t not in stopwords.words('english')]  # remove stopwords\n",
    "    # remove any digits, i.e. \"3rd edition\"\n",
    "    tokens = [t for t in tokens if not any(c.isdigit() for c in t)]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# reviews_df['processed_comments'] = reviews_df['comments'].apply(lambda s: my_tokenizer(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8237837837837838"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating our positively rated reviews\n",
    "reviews_df['Positively Rated'] = reviews_df['label'].apply(lambda c: 1 if c == 'pos' else 0)\n",
    "reviews_df['Positively Rated'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceUserId</th>\n",
       "      <th>reviews_by_rating</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>number_of_rating</th>\n",
       "      <th>MentionEnglish</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>KeyTerms</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Growth</th>\n",
       "      <th>...</th>\n",
       "      <th>product_description</th>\n",
       "      <th>TopicLevel1Id</th>\n",
       "      <th>TopicLevel2Id</th>\n",
       "      <th>TopicLevel3Id</th>\n",
       "      <th>user</th>\n",
       "      <th>comments</th>\n",
       "      <th>reaction</th>\n",
       "      <th>comment_rating</th>\n",
       "      <th>scores</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B004N5J568</td>\n",
       "      <td>[{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4836</td>\n",
       "      <td>182.0</td>\n",
       "      <td>Scharffen Berger Natural Unsweetened Cocoa Pow...</td>\n",
       "      <td>pos</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Susie's</td>\n",
       "      <td>So glad I discovered Scharffen Berger.  For a ...</td>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9190</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B004N5J568</td>\n",
       "      <td>[{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4836</td>\n",
       "      <td>182.0</td>\n",
       "      <td>Scharffen Berger Natural Unsweetened Cocoa Pow...</td>\n",
       "      <td>pos</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aja</td>\n",
       "      <td>I have been trying many different brands of ch...</td>\n",
       "      <td>17</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9767</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B004N5J568</td>\n",
       "      <td>[{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4836</td>\n",
       "      <td>182.0</td>\n",
       "      <td>Scharffen Berger Natural Unsweetened Cocoa Pow...</td>\n",
       "      <td>pos</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TonyD</td>\n",
       "      <td>Tried many types of cocoa to make chocolate an...</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B004N5J568</td>\n",
       "      <td>[{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4836</td>\n",
       "      <td>182.0</td>\n",
       "      <td>Scharffen Berger Natural Unsweetened Cocoa Pow...</td>\n",
       "      <td>pos</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sharron</td>\n",
       "      <td>We find this cocoa powder  has a delicate text...</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0516</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B004N5J568</td>\n",
       "      <td>[{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4836</td>\n",
       "      <td>182.0</td>\n",
       "      <td>Scharffen Berger Natural Unsweetened Cocoa Pow...</td>\n",
       "      <td>pos</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wizdum</td>\n",
       "      <td>Baked a gourmet gluten free chocolate cake wit...</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8439</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  SourceUserId                                  reviews_by_rating  \\\n",
       "0   B004N5J568  [{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...   \n",
       "1   B004N5J568  [{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...   \n",
       "2   B004N5J568  [{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...   \n",
       "3   B004N5J568  [{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...   \n",
       "4   B004N5J568  [{'5 star': '92%'}, {'4 star': '4%'}, {'3 star...   \n",
       "\n",
       "   average_rating  number_of_reviews  number_of_rating  \\\n",
       "0             4.9               4836             182.0   \n",
       "1             4.9               4836             182.0   \n",
       "2             4.9               4836             182.0   \n",
       "3             4.9               4836             182.0   \n",
       "4             4.9               4836             182.0   \n",
       "\n",
       "                                      MentionEnglish Sentiment KeyTerms  \\\n",
       "0  Scharffen Berger Natural Unsweetened Cocoa Pow...       pos    cocoa   \n",
       "1  Scharffen Berger Natural Unsweetened Cocoa Pow...       pos    cocoa   \n",
       "2  Scharffen Berger Natural Unsweetened Cocoa Pow...       pos    cocoa   \n",
       "3  Scharffen Berger Natural Unsweetened Cocoa Pow...       pos    cocoa   \n",
       "4  Scharffen Berger Natural Unsweetened Cocoa Pow...       pos    cocoa   \n",
       "\n",
       "   Quantity  Growth  ... product_description  TopicLevel1Id  TopicLevel2Id  \\\n",
       "0       255       0  ...                 NaN            NaN            NaN   \n",
       "1       255       0  ...                 NaN            NaN            NaN   \n",
       "2       255       0  ...                 NaN            NaN            NaN   \n",
       "3       255       0  ...                 NaN            NaN            NaN   \n",
       "4       255       0  ...                 NaN            NaN            NaN   \n",
       "\n",
       "   TopicLevel3Id     user                                           comments  \\\n",
       "0            NaN  Susie's  So glad I discovered Scharffen Berger.  For a ...   \n",
       "1            NaN      Aja  I have been trying many different brands of ch...   \n",
       "2            NaN    TonyD  Tried many types of cocoa to make chocolate an...   \n",
       "3            NaN  sharron  We find this cocoa powder  has a delicate text...   \n",
       "4            NaN   Wizdum  Baked a gourmet gluten free chocolate cake wit...   \n",
       "\n",
       "  reaction comment_rating  scores  label  \n",
       "0        8            5.0  0.9190    pos  \n",
       "1       17            5.0  0.9767    pos  \n",
       "2        4            5.0  0.3612    pos  \n",
       "3        2            5.0  0.0516    pos  \n",
       "4        1            5.0  0.8439    pos  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews_df['comments'], reviews_df['Positively Rated'], random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train first entry: \n",
      "\n",
      " So glad I discovered Scharffen Berger.  For a while I was turned off by the price, but it is worth every penny!  Not only is it fantastic for hot cocoa--especially with Peak Milk Powder--, it makes fantastic truffles.  I also mix it with cocoa butter and a little pure maple syrup to dip strawberries.  (The cocoa butter helps the chocolate to set.)  No chocolate to melt and it couldn't be easier.  If your coconut butter is a little hard, you can mix it together then microwave for a few seconds before dipping in the berries. Read more\n",
      "\n",
      "\n",
      "X_train shape:  (568,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train first entry: \\n\\n', X_train[0])\n",
    "print('\\n\\nX_train shape: ', X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#Tfidf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "vect = CountVectorizer().fit(X_train)\n",
    "\n",
    "# Fit the TfidfVectorizer to the training data specifiying a minimum document frequency of 5\n",
    "# vect = TfidfVectorizer(min_df = 5).fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000',\n",
       " '0ah',\n",
       " '0g',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '100hz',\n",
       " '100s',\n",
       " '105',\n",
       " '10g',\n",
       " '10k',\n",
       " '11',\n",
       " '110pds',\n",
       " '115',\n",
       " '117',\n",
       " '12',\n",
       " '120',\n",
       " '1200',\n",
       " '124',\n",
       " '12th',\n",
       " '13',\n",
       " '13g',\n",
       " '14',\n",
       " '141',\n",
       " '142',\n",
       " '14g',\n",
       " '14th',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '154',\n",
       " '15g',\n",
       " '16',\n",
       " '160',\n",
       " '17',\n",
       " '170',\n",
       " '174',\n",
       " '180',\n",
       " '18oz',\n",
       " '18v',\n",
       " '19',\n",
       " '1916',\n",
       " '1940',\n",
       " '1940s',\n",
       " '1942',\n",
       " '1945',\n",
       " '1947',\n",
       " '1948',\n",
       " '1957',\n",
       " '1962',\n",
       " '1964',\n",
       " '1965',\n",
       " '1966',\n",
       " '1970',\n",
       " '1986',\n",
       " '1992',\n",
       " '1g',\n",
       " '1st',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2004',\n",
       " '2009',\n",
       " '2010',\n",
       " '2014',\n",
       " '2016',\n",
       " '2017',\n",
       " '2018',\n",
       " '2019',\n",
       " '2020',\n",
       " '2021',\n",
       " '204',\n",
       " '20g',\n",
       " '20gms',\n",
       " '20v',\n",
       " '20volt',\n",
       " '22',\n",
       " '224',\n",
       " '225',\n",
       " '24',\n",
       " '240mph',\n",
       " '25',\n",
       " '250',\n",
       " '25kg',\n",
       " '26',\n",
       " '27',\n",
       " '272',\n",
       " '28',\n",
       " '2a',\n",
       " '2g',\n",
       " '2k',\n",
       " '2nd',\n",
       " '2x4',\n",
       " '30',\n",
       " '3000',\n",
       " '3004',\n",
       " '30am',\n",
       " '30hz',\n",
       " '30minutes',\n",
       " '313',\n",
       " '319',\n",
       " '32',\n",
       " '340',\n",
       " '35',\n",
       " '350',\n",
       " '36',\n",
       " '36v',\n",
       " '37',\n",
       " '3d',\n",
       " '3rd',\n",
       " '3x5',\n",
       " '40',\n",
       " '4000',\n",
       " '40v',\n",
       " '41',\n",
       " '4237',\n",
       " '43',\n",
       " '45',\n",
       " '48',\n",
       " '48cc',\n",
       " '4g',\n",
       " '4k',\n",
       " '4oz',\n",
       " '4th',\n",
       " '4x',\n",
       " '4x4',\n",
       " '4x4s',\n",
       " '50',\n",
       " '500',\n",
       " '50lbs',\n",
       " '5a',\n",
       " '5db',\n",
       " '5g',\n",
       " '5s',\n",
       " '5ths',\n",
       " '5x11',\n",
       " '5x5',\n",
       " '60',\n",
       " '600',\n",
       " '6000',\n",
       " '60hz',\n",
       " '60v',\n",
       " '63',\n",
       " '64',\n",
       " '68',\n",
       " '6ah',\n",
       " '6am',\n",
       " '6ft',\n",
       " '6g',\n",
       " '6th',\n",
       " '6x9',\n",
       " '70',\n",
       " '71',\n",
       " '7500d',\n",
       " '7g',\n",
       " '800cfm',\n",
       " '8g',\n",
       " '8oz',\n",
       " '8pm',\n",
       " '90',\n",
       " '95',\n",
       " '96',\n",
       " '98',\n",
       " '99',\n",
       " '9ah',\n",
       " 'aaron',\n",
       " 'ab',\n",
       " 'aback',\n",
       " 'abandoned',\n",
       " 'abandoning',\n",
       " 'abbreviated',\n",
       " 'abdomen',\n",
       " 'abdominal',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abrupt',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'absolutely',\n",
       " 'absorb',\n",
       " 'abstraction',\n",
       " 'absurdist',\n",
       " 'abundantly',\n",
       " 'academic',\n",
       " 'acai',\n",
       " 'accelerated',\n",
       " 'accent',\n",
       " 'accents',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'access',\n",
       " 'accessible',\n",
       " 'accessories',\n",
       " 'accident',\n",
       " 'accidentally',\n",
       " 'accommodating',\n",
       " 'accompany',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishing',\n",
       " 'accomplishments',\n",
       " 'according',\n",
       " 'account',\n",
       " 'accountability',\n",
       " 'accountable',\n",
       " 'accounts',\n",
       " 'accurate',\n",
       " 'achievable',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievements',\n",
       " 'acne',\n",
       " 'acoustic',\n",
       " 'acoustik',\n",
       " 'acquiring',\n",
       " 'acre',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actionable',\n",
       " 'actions',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activities',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'actress',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'acurate',\n",
       " 'ad',\n",
       " 'adapter',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addicted',\n",
       " 'addiction',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additions',\n",
       " 'additives',\n",
       " 'addresses',\n",
       " 'adds',\n",
       " 'adequate',\n",
       " 'adichi',\n",
       " 'adichie',\n",
       " 'aditchie',\n",
       " 'adjoining',\n",
       " 'adjunct',\n",
       " 'adjust',\n",
       " 'adjustable',\n",
       " 'adjusted',\n",
       " 'administration',\n",
       " 'administrators',\n",
       " 'admired',\n",
       " 'admit',\n",
       " 'admits',\n",
       " 'admittedly',\n",
       " 'adolescence',\n",
       " 'adolescent',\n",
       " 'adopted',\n",
       " 'adorable',\n",
       " 'adore',\n",
       " 'adult',\n",
       " 'adults',\n",
       " 'advanced',\n",
       " 'advances',\n",
       " 'advantage',\n",
       " 'adventure',\n",
       " 'adventures',\n",
       " 'adversity',\n",
       " 'advertise',\n",
       " 'advertised',\n",
       " 'advertisement',\n",
       " 'advertisements',\n",
       " 'advertisers',\n",
       " 'advertises',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advices',\n",
       " 'aesthetic',\n",
       " 'aesthetically',\n",
       " 'af',\n",
       " 'affairs',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affirmations',\n",
       " 'affirming',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'aforemention',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'after',\n",
       " 'aftermarket',\n",
       " 'afternoon',\n",
       " 'aftersale',\n",
       " 'aftertaste',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'agent',\n",
       " 'ages',\n",
       " 'aggravating',\n",
       " 'aggravation',\n",
       " 'aggressive',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreeable',\n",
       " 'agua',\n",
       " 'ah',\n",
       " 'aha',\n",
       " 'ahead',\n",
       " 'aimed',\n",
       " 'ain',\n",
       " 'aint',\n",
       " 'aip',\n",
       " 'air',\n",
       " 'aired',\n",
       " 'airflow',\n",
       " 'aka',\n",
       " 'akin',\n",
       " 'albeit',\n",
       " 'album',\n",
       " 'alcali',\n",
       " 'alcohol',\n",
       " 'alert',\n",
       " 'alerted',\n",
       " 'alexandra',\n",
       " 'algerian',\n",
       " 'align',\n",
       " 'aligned',\n",
       " 'alike',\n",
       " 'alive',\n",
       " 'alkali',\n",
       " 'alkaline',\n",
       " 'all',\n",
       " 'allergen',\n",
       " 'allergens',\n",
       " 'allergic',\n",
       " 'allergies',\n",
       " 'allergy',\n",
       " 'alley',\n",
       " 'allison',\n",
       " 'allnock',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allows',\n",
       " 'allspice',\n",
       " 'almond',\n",
       " 'almost',\n",
       " 'aloha',\n",
       " 'alohas',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alongside',\n",
       " 'alot',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'also',\n",
       " 'alter',\n",
       " 'altering',\n",
       " 'alternates',\n",
       " 'alternating',\n",
       " 'alternative',\n",
       " 'alternatives',\n",
       " 'although',\n",
       " 'always',\n",
       " 'alzheimer',\n",
       " 'am',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazon',\n",
       " 'ambers',\n",
       " 'ambitions',\n",
       " 'ambridge',\n",
       " 'amending',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americanah',\n",
       " 'amid',\n",
       " 'among',\n",
       " 'amount',\n",
       " 'amp',\n",
       " 'amusing',\n",
       " 'an',\n",
       " 'anachronistic',\n",
       " 'anal',\n",
       " 'analyse',\n",
       " 'analysed',\n",
       " 'analysis',\n",
       " 'analyzing',\n",
       " 'anchored',\n",
       " 'and',\n",
       " 'andrew',\n",
       " 'andrews',\n",
       " 'andy',\n",
       " 'anecdotes',\n",
       " 'angelic',\n",
       " 'angelica',\n",
       " 'anger',\n",
       " 'angle',\n",
       " 'angled',\n",
       " 'angles',\n",
       " 'anglican',\n",
       " 'angry',\n",
       " 'angst',\n",
       " 'animated',\n",
       " 'annie',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answers',\n",
       " 'anticipated',\n",
       " 'antidote',\n",
       " 'antioxidants',\n",
       " 'antonio',\n",
       " 'anxiety',\n",
       " 'any',\n",
       " 'anyhow',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywear',\n",
       " 'anywhere',\n",
       " 'ap',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'aperture',\n",
       " 'apologetics',\n",
       " 'apostasy',\n",
       " 'apostles',\n",
       " 'apostolic',\n",
       " 'app',\n",
       " 'appalachia',\n",
       " 'apparently',\n",
       " 'appealing',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appeared',\n",
       " 'appears',\n",
       " 'appendix',\n",
       " 'appetite',\n",
       " 'apple',\n",
       " 'apples',\n",
       " 'appliance',\n",
       " 'application',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciation',\n",
       " 'approach',\n",
       " 'approaching',\n",
       " 'appropriate',\n",
       " 'approx',\n",
       " 'april',\n",
       " 'après',\n",
       " 'ar',\n",
       " 'aran',\n",
       " 'arc',\n",
       " 'arch',\n",
       " 'archetype',\n",
       " 'archive',\n",
       " 'arcs',\n",
       " 'are',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'aren',\n",
       " 'argument',\n",
       " 'arguments',\n",
       " 'ariel',\n",
       " 'armor',\n",
       " 'armrest',\n",
       " 'armrests',\n",
       " 'arms',\n",
       " 'around',\n",
       " 'arquette',\n",
       " 'arquettes',\n",
       " 'arrays',\n",
       " 'arrested',\n",
       " 'arrival',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrives',\n",
       " 'art',\n",
       " 'artbook',\n",
       " 'artbooks',\n",
       " 'arteries',\n",
       " 'artful',\n",
       " 'arthritis',\n",
       " 'article',\n",
       " 'articles',\n",
       " 'artificial',\n",
       " 'artist',\n",
       " 'arts',\n",
       " 'artwork',\n",
       " 'as',\n",
       " 'ash',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'asks',\n",
       " 'aspartame',\n",
       " 'aspect',\n",
       " 'aspects',\n",
       " 'aspirations',\n",
       " 'ass',\n",
       " 'assemble',\n",
       " 'assembled',\n",
       " 'assembler',\n",
       " 'assembling',\n",
       " 'assembly',\n",
       " 'assent',\n",
       " 'assignment',\n",
       " 'assignments',\n",
       " 'assist',\n",
       " 'assistant',\n",
       " 'assisted',\n",
       " 'associated',\n",
       " 'assorted',\n",
       " 'assortment',\n",
       " 'assortments',\n",
       " 'assume',\n",
       " 'assumed',\n",
       " 'assuming',\n",
       " 'assumptions',\n",
       " 'assures',\n",
       " 'asteroids',\n",
       " 'asymptomatic',\n",
       " 'at',\n",
       " 'ate',\n",
       " 'atlanta',\n",
       " 'atmos',\n",
       " 'atomic',\n",
       " 'attach',\n",
       " 'attached',\n",
       " 'attaching',\n",
       " 'attachment',\n",
       " 'attachments',\n",
       " 'attacked',\n",
       " 'attacking',\n",
       " 'attacks',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attempts',\n",
       " 'attended',\n",
       " 'attention',\n",
       " 'attitude',\n",
       " 'attitudes',\n",
       " 'attract',\n",
       " 'attractive',\n",
       " 'attractively',\n",
       " 'attracts',\n",
       " 'attributes',\n",
       " 'attunement',\n",
       " 'auctions',\n",
       " 'audible',\n",
       " 'audience',\n",
       " 'audio',\n",
       " 'audiophile',\n",
       " 'audiopipe',\n",
       " 'august',\n",
       " 'authentic',\n",
       " 'authenticity',\n",
       " 'author',\n",
       " 'authority',\n",
       " 'authorize',\n",
       " 'authors',\n",
       " 'autobiographical',\n",
       " 'autobiography',\n",
       " 'automata',\n",
       " 'automatic',\n",
       " 'automatically',\n",
       " 'autumn',\n",
       " 'available',\n",
       " 'avant',\n",
       " 'avenue',\n",
       " 'average',\n",
       " 'avic',\n",
       " 'avid',\n",
       " 'avoid',\n",
       " 'awaken',\n",
       " 'award',\n",
       " 'awareness',\n",
       " 'away',\n",
       " 'aways',\n",
       " 'awe',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awhile',\n",
       " 'awkward',\n",
       " 'axial',\n",
       " 'ayuda',\n",
       " 'b003fw4xje',\n",
       " 'b07nq6dfld',\n",
       " 'b4',\n",
       " 'baby',\n",
       " 'bach',\n",
       " 'bachelor',\n",
       " 'back',\n",
       " 'backdrops',\n",
       " 'backed',\n",
       " 'background',\n",
       " 'backpack',\n",
       " 'backs',\n",
       " 'backtesting',\n",
       " 'backtrack',\n",
       " 'backups',\n",
       " 'backward',\n",
       " 'backwards',\n",
       " 'backyard',\n",
       " 'bacon',\n",
       " 'bad',\n",
       " 'badly',\n",
       " 'bag',\n",
       " 'bagged',\n",
       " 'bags',\n",
       " 'bah',\n",
       " 'baked',\n",
       " 'baking',\n",
       " 'balance',\n",
       " 'balanced',\n",
       " 'balancing',\n",
       " 'ball',\n",
       " 'bamf',\n",
       " 'banana',\n",
       " 'band',\n",
       " 'bang',\n",
       " 'banged',\n",
       " 'bank',\n",
       " 'banna',\n",
       " 'banquet',\n",
       " 'bar',\n",
       " 'barbed',\n",
       " 'barcode',\n",
       " 'barely',\n",
       " 'bares',\n",
       " 'barest',\n",
       " 'bargain',\n",
       " 'barn',\n",
       " 'barrel',\n",
       " 'barrier',\n",
       " 'bars',\n",
       " 'barth',\n",
       " 'base',\n",
       " 'based',\n",
       " 'basel',\n",
       " 'basement',\n",
       " 'bases',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basics',\n",
       " 'basis',\n",
       " 'basquiat',\n",
       " 'bass',\n",
       " 'bat',\n",
       " 'batch',\n",
       " 'bathroom',\n",
       " 'battered',\n",
       " 'batteries',\n",
       " 'battery',\n",
       " 'battle',\n",
       " 'bawdily',\n",
       " 'bawling',\n",
       " 'bc',\n",
       " 'be',\n",
       " 'beam',\n",
       " 'bean',\n",
       " 'beans',\n",
       " 'bear',\n",
       " 'beast',\n",
       " 'beat',\n",
       " 'beats',\n",
       " 'beauties',\n",
       " 'beautiful',\n",
       " 'beautifully',\n",
       " 'beauty',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'bed',\n",
       " 'bedrock',\n",
       " 'beds',\n",
       " 'beef',\n",
       " 'been',\n",
       " 'beets',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'began',\n",
       " 'begin',\n",
       " 'beginner',\n",
       " 'beginning',\n",
       " 'beginnings',\n",
       " 'begins',\n",
       " 'behaviors',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'beings',\n",
       " 'belcher',\n",
       " 'beliefs',\n",
       " 'believe',\n",
       " 'believed',\n",
       " 'believer',\n",
       " 'believes',\n",
       " 'believing',\n",
       " 'bella',\n",
       " 'beloved',\n",
       " 'below',\n",
       " 'belt',\n",
       " 'bemoaned',\n",
       " 'ben',\n",
       " 'bend',\n",
       " 'bending',\n",
       " 'benefit',\n",
       " 'benefited',\n",
       " 'benefits',\n",
       " 'bennett',\n",
       " 'bent',\n",
       " 'berating',\n",
       " 'berger',\n",
       " 'bernhard',\n",
       " 'berries',\n",
       " 'berry',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'beta',\n",
       " 'better',\n",
       " 'between',\n",
       " 'beverage',\n",
       " 'beware',\n",
       " 'beyond',\n",
       " 'bg',\n",
       " 'bible',\n",
       " 'bibles',\n",
       " 'biblical',\n",
       " 'bic',\n",
       " 'bicycling',\n",
       " 'bien',\n",
       " 'big',\n",
       " 'bigal',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'biggs',\n",
       " 'bikini',\n",
       " 'bill',\n",
       " 'billed',\n",
       " 'billy',\n",
       " 'binder',\n",
       " 'binding',\n",
       " 'biography',\n",
       " 'biological',\n",
       " 'bird',\n",
       " 'birds',\n",
       " 'birth',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " 'bite',\n",
       " 'bites',\n",
       " 'biting',\n",
       " 'bits',\n",
       " 'bitter',\n",
       " 'bitting',\n",
       " 'bix',\n",
       " 'black',\n",
       " 'blacks',\n",
       " 'blade',\n",
       " 'bladed',\n",
       " 'blades',\n",
       " 'blah',\n",
       " 'blame',\n",
       " 'bland',\n",
       " 'blast',\n",
       " 'blasts',\n",
       " 'bleed',\n",
       " 'blend',\n",
       " 'blended',\n",
       " 'blender',\n",
       " 'blends',\n",
       " 'bless',\n",
       " 'blessed',\n",
       " 'blessings',\n",
       " 'blew',\n",
       " 'blind',\n",
       " 'blinking',\n",
       " 'blinks',\n",
       " 'bloat',\n",
       " 'bloating',\n",
       " 'block',\n",
       " 'blocked',\n",
       " 'blocks',\n",
       " 'blog',\n",
       " 'blogged',\n",
       " 'blogger',\n",
       " 'bloggers',\n",
       " 'blogging',\n",
       " 'blogs',\n",
       " 'blood',\n",
       " 'blow',\n",
       " 'blower',\n",
       " 'blowers',\n",
       " 'blowing',\n",
       " 'blown',\n",
       " 'blows',\n",
       " 'blue',\n",
       " 'blueberry',\n",
       " 'blueray',\n",
       " 'bluntly',\n",
       " 'blurred',\n",
       " 'board',\n",
       " 'boards',\n",
       " 'boddicker',\n",
       " 'bodies',\n",
       " 'body',\n",
       " 'bogged',\n",
       " 'boggling',\n",
       " 'bold',\n",
       " 'boldly',\n",
       " 'bolt',\n",
       " 'bolted',\n",
       " 'bomb',\n",
       " 'bombs',\n",
       " 'bon',\n",
       " 'bonbons',\n",
       " 'bond',\n",
       " 'bone',\n",
       " 'bones',\n",
       " 'bonkers',\n",
       " 'bonne',\n",
       " 'bonus',\n",
       " 'book',\n",
       " 'booklet',\n",
       " 'books',\n",
       " 'bookshelf',\n",
       " 'boom',\n",
       " 'boomerangs',\n",
       " 'boomy',\n",
       " 'boost',\n",
       " 'boot',\n",
       " 'bootleg',\n",
       " 'bore',\n",
       " 'bored',\n",
       " 'boring',\n",
       " 'born',\n",
       " 'boss',\n",
       " 'bosses',\n",
       " 'botanica',\n",
       " 'both',\n",
       " 'bother',\n",
       " 'bothered',\n",
       " 'bothers',\n",
       " 'bottle',\n",
       " 'bottom',\n",
       " 'bought',\n",
       " 'bouncing',\n",
       " 'bound',\n",
       " 'boutiquish',\n",
       " 'bowels',\n",
       " 'bowersock',\n",
       " 'bowl',\n",
       " 'bowling',\n",
       " 'box',\n",
       " 'boxed',\n",
       " 'boxes',\n",
       " 'boy',\n",
       " 'boyght',\n",
       " 'boys',\n",
       " 'bracket',\n",
       " 'brackets',\n",
       " 'braid',\n",
       " 'brain',\n",
       " 'branch',\n",
       " 'brand',\n",
       " 'brands',\n",
       " 'bravely',\n",
       " 'bravo',\n",
       " 'brawl',\n",
       " 'brazil',\n",
       " 'breadth',\n",
       " 'break',\n",
       " 'breakdown',\n",
       " 'breakfast',\n",
       " 'breaking',\n",
       " 'breaks',\n",
       " 'breast',\n",
       " 'breath',\n",
       " 'breathe',\n",
       " 'breathing',\n",
       " 'breaths',\n",
       " 'breeze',\n",
       " 'breezy',\n",
       " 'brene',\n",
       " 'breville',\n",
       " 'brew',\n",
       " 'brewed',\n",
       " 'brewing',\n",
       " 'brick',\n",
       " 'bridged',\n",
       " 'bridget',\n",
       " 'brief',\n",
       " 'bright',\n",
       " 'brighter',\n",
       " 'brightly',\n",
       " 'brightness',\n",
       " 'brilliant',\n",
       " 'brimming',\n",
       " 'bring',\n",
       " 'bringing',\n",
       " 'brings',\n",
       " 'broad',\n",
       " 'broadcast',\n",
       " 'broadcasting',\n",
       " 'broke',\n",
       " 'brokeback',\n",
       " 'broken',\n",
       " 'brokenness',\n",
       " 'brooklyn',\n",
       " 'broom',\n",
       " 'brother',\n",
       " 'brothers',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'brownie',\n",
       " 'brownies',\n",
       " 'browser',\n",
       " 'brush',\n",
       " 'brute',\n",
       " 'brûlée',\n",
       " 'bts',\n",
       " 'btw',\n",
       " 'bubblewrap',\n",
       " 'buck',\n",
       " 'bud',\n",
       " 'budget',\n",
       " 'buds',\n",
       " 'buena',\n",
       " 'bueno',\n",
       " 'buffer',\n",
       " 'bugs',\n",
       " 'build',\n",
       " 'building',\n",
       " 'builds',\n",
       " 'built',\n",
       " 'bulb',\n",
       " 'bulbs',\n",
       " 'bulk',\n",
       " 'bulky',\n",
       " 'bullet',\n",
       " 'bummer',\n",
       " 'bump',\n",
       " 'bunch',\n",
       " 'bunny',\n",
       " 'burbs',\n",
       " 'burdensome',\n",
       " 'burge',\n",
       " 'burned',\n",
       " 'burning',\n",
       " 'burnout',\n",
       " 'burns',\n",
       " 'burnt',\n",
       " 'bush',\n",
       " 'business',\n",
       " 'busy',\n",
       " 'but',\n",
       " 'butter',\n",
       " 'button',\n",
       " 'buttons',\n",
       " 'buy',\n",
       " 'buyers',\n",
       " 'buying',\n",
       " 'by',\n",
       " 'byline',\n",
       " 'cab',\n",
       " 'cabinet',\n",
       " 'cable',\n",
       " 'cables',\n",
       " 'cabs',\n",
       " 'cacao',\n",
       " 'cachet',\n",
       " 'cactus',\n",
       " 'cad',\n",
       " 'caffeine',\n",
       " 'cage',\n",
       " 'cages',\n",
       " 'cake',\n",
       " 'caked',\n",
       " 'cal',\n",
       " ...]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6981"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<568x6981 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 38767 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the documents in the training data to a document-term matrix\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "X_test_vectorized = vect.transform(X_test)\n",
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.6013317892298784\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# support vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC accuracy:  82.63%\n",
      "Accuracy Score: 0.8263157894736842 / Precision Score 0.8263157894736842 / recall_score 1.0\n",
      "Confusion  matrix:\n",
      " [[  0  33]\n",
      " [  0 157]]\n"
     ]
    }
   ],
   "source": [
    "# support vector\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(random_state= 1)\n",
    "svm.fit(X_train_vectorized, y_train)\n",
    "print(\"SVC accuracy: {: .2f}%\".format(svm.score(X_test_vectorized, y_test)*100))\n",
    "y_pred = svm.predict(X_test_vectorized)\n",
    "print('Accuracy Score: {} / Precision Score {} / recall_score {}'. format(accuracy_score(y_test, y_pred),\n",
    "                                                                      precision_score(y_test, y_pred),\n",
    "                                                                      recall_score(y_test, y_pred)))\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion  matrix:\\n {}'.format(cnf_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB accuracy:  79.47%\n",
      "Accuracy Score: 0.7947368421052632 / Precision Score 0.8390804597701149 / recall_score 0.9299363057324841\n",
      "Confusion  matrix:\n",
      " [[  5  28]\n",
      " [ 11 146]]\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "# nb= GaussianNB()\n",
    "nb= MultinomialNB()\n",
    "nb.fit(X_train_vectorized, y_train)\n",
    "print(\"NB accuracy: {: .2f}%\".format(nb.score(X_test_vectorized, y_test)*100))\n",
    "y_pred = nb.predict(X_test_vectorized)\n",
    "print('Accuracy Score: {} / Precision Score {} / recall_score {}'. format(accuracy_score(y_test, y_pred),\n",
    "                                                                      precision_score(y_test, y_pred),\n",
    "                                                                      recall_score(y_test, y_pred)))\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion  matrix:\\n {}'.format(cnf_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN accuracy:  82.11%\n",
      "Accuracy Score: 0.8210526315789474 / Precision Score 0.8360655737704918 / recall_score 0.9745222929936306\n",
      "Confusion  matrix:\n",
      " [[  3  30]\n",
      " [  4 153]]\n"
     ]
    }
   ],
   "source": [
    "#KNN model\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn= KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(X_train_vectorized, y_train)\n",
    "print(\"KNN accuracy: {: .2f}%\".format(knn.score(X_test_vectorized, y_test)*100))\n",
    "y_pred = knn.predict(X_test_vectorized)\n",
    "print('Accuracy Score: {} / Precision Score {} / recall_score {}'. format(accuracy_score(y_test, y_pred),\n",
    "                                                                      precision_score(y_test, y_pred),\n",
    "                                                                      recall_score(y_test, y_pred)))\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion  matrix:\\n {}'.format(cnf_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy:  82.63%\n",
      "Accuracy Score: 0.8263157894736842 / Precision Score 0.8263157894736842 / recall_score 1.0\n",
      "Confusion  matrix:\n",
      " [[  0  33]\n",
      " [  0 157]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 100, random_state = 1)\n",
    "rf.fit(X_train_vectorized, y_train)\n",
    "print(\"Random Forest accuracy: {: .2f}%\".format(rf.score(X_test_vectorized, y_test)*100))\n",
    "y_pred = rf.predict(X_test_vectorized)\n",
    "print('Accuracy Score: {} / Precision Score {} / recall_score {}'. format(accuracy_score(y_test, y_pred),\n",
    "                                                                      precision_score(y_test, y_pred),\n",
    "                                                                      recall_score(y_test, y_pred)))\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion  matrix:\\n {}'.format(cnf_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid RandomizedSearchCV will search over\n",
    "grid = {\"n_estimators\": [10, 100, 200, 500, 1000, 1200],\n",
    "        \"max_depth\": [None, 5, 10, 20, 30],\n",
    "        \"max_features\": [\"auto\", \"sqrt\"],\n",
    "        \"min_samples_split\": [2, 4, 6],\n",
    "        \"min_samples_leaf\": [1, 2, 4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10, total=   0.2s\n",
      "[CV] n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10, total=   0.2s\n",
      "[CV] n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10, total=   0.2s\n",
      "[CV] n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10, total=   0.2s\n",
      "[CV] n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10, total=   0.2s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   0.3s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   0.4s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   0.3s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   0.3s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   0.3s\n",
      "[CV] n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30, total=   3.8s\n",
      "[CV] n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30, total=   3.6s\n",
      "[CV] n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30, total=   3.5s\n",
      "[CV] n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30, total=   3.7s\n",
      "[CV] n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30, total=   3.7s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   0.6s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   0.6s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   0.6s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   0.6s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   0.6s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=30, total=   0.2s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=30, total=   0.2s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=30, total=   0.3s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=30, total=   0.3s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=30, total=   0.2s\n",
      "[CV] n_estimators=1200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=1200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   3.8s\n",
      "[CV] n_estimators=1200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=1200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   3.8s\n",
      "[CV] n_estimators=1200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=1200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   3.8s\n",
      "[CV] n_estimators=1200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=1200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   4.0s\n",
      "[CV] n_estimators=1200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=1200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   3.6s\n",
      "[CV] n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=10, total=   1.2s\n",
      "[CV] n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=10, total=   1.2s\n",
      "[CV] n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=10, total=   1.3s\n",
      "[CV] n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=10, total=   1.1s\n",
      "[CV] n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=10, total=   1.2s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=20, total=   2.3s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=20, total=   2.4s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=20, total=   2.4s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=20, total=   2.3s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=20, total=   2.7s\n",
      "[CV] n_estimators=10, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=10, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=20, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=10, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=20, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=10, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=20, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=10, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=20, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=10, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=20, total=   0.0s\n",
      "[CV] n_estimators=1200, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1200, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, total=   3.6s\n",
      "[CV] n_estimators=1200, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=1200, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, total=   3.9s\n",
      "[CV] n_estimators=1200, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=1200, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, total=   3.9s\n",
      "[CV] n_estimators=1200, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=1200, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, total=   3.4s\n",
      "[CV] n_estimators=1200, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=1200, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, total=   3.5s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=None, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=None, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=None, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=None, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=None, total=   0.0s\n",
      "[CV] n_estimators=500, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=5 \n",
      "[CV]  n_estimators=500, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=5, total=   0.9s\n",
      "[CV] n_estimators=500, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=5 \n",
      "[CV]  n_estimators=500, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=5, total=   0.9s\n",
      "[CV] n_estimators=500, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=5 \n",
      "[CV]  n_estimators=500, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=5, total=   0.9s\n",
      "[CV] n_estimators=500, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=5 \n",
      "[CV]  n_estimators=500, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=5, total=   0.9s\n",
      "[CV] n_estimators=500, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=5 \n",
      "[CV]  n_estimators=500, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=5, total=   1.2s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=20, total=   0.6s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=20, total=   0.6s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=20, total=   0.5s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=20, total=   0.5s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=20, total=   0.5s\n",
      "[CV] n_estimators=500, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=500, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   1.6s\n",
      "[CV] n_estimators=500, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=500, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   1.5s\n",
      "[CV] n_estimators=500, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=500, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   1.6s\n",
      "[CV] n_estimators=500, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=500, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   1.5s\n",
      "[CV] n_estimators=500, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=500, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   1.5s\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=10, total=   0.5s\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=10, total=   0.4s\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=10, total=   0.5s\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=10, total=   0.5s\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=10, total=   0.6s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5, total=   1.0s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5, total=   0.9s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5, total=   0.9s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5, total=   1.0s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5, total=   0.9s\n",
      "[CV] n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=30, total=   0.7s\n",
      "[CV] n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=30, total=   0.7s\n",
      "[CV] n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=30, total=   0.7s\n",
      "[CV] n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=30, total=   0.7s\n",
      "[CV] n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=30, total=   0.8s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=None \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=None, total=   2.9s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=None, total=   2.8s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=None, total=   2.9s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=None, total=   3.1s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=None, total=   3.0s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=30, total=   2.3s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=30, total=   2.3s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=30, total=   2.3s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=30, total=   2.3s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=30, total=   2.4s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=None, total=   0.4s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=None, total=   0.4s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=None, total=   0.4s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=None, total=   0.5s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=None, total=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  2.3min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set n_jobs to -1 to use all cores (NOTE: n_jobs=-1 is broken as of 8 Dec 2019, using n_jobs=1 works)\n",
    "clf = RandomForestClassifier(n_jobs=1)\n",
    "\n",
    "# Setup RandomizedSearchCV\n",
    "rs_clf = RandomizedSearchCV(estimator=clf,\n",
    "                            param_distributions=grid,\n",
    "                            n_iter=20, # try 20 models total\n",
    "                            cv=5, # 5-fold cross-validation\n",
    "                            verbose=2) # print out results\n",
    "\n",
    "# Fit the RandomizedSearchCV version of clf\n",
    "rs_clf.fit(X_train_vectorized, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 10,\n",
       " 'min_samples_split': 4,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': None}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy:  84.74%\n",
      "Accuracy Score: 0.8473684210526315 / Precision Score 0.8440860215053764 / recall_score 1.0\n",
      "Confusion  matrix:\n",
      " [[  4  29]\n",
      " [  0 157]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(**rs_clf.best_params_)\n",
    "rf.fit(X_train_vectorized, y_train)\n",
    "print(\"Random Forest accuracy: {: .2f}%\".format(rf.score(X_test_vectorized, y_test)*100))\n",
    "y_pred = rf.predict(X_test_vectorized)\n",
    "print('Accuracy Score: {} / Precision Score {} / recall_score {}'. format(accuracy_score(y_test, y_pred),\n",
    "                                                                      precision_score(y_test, y_pred),\n",
    "                                                                      recall_score(y_test, y_pred)))\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion  matrix:\\n {}'.format(cnf_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AYODE\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:38:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " XG boost:  83.68%\n",
      "Accuracy Score: 0.8368421052631579 / Precision Score 0.8579545454545454 / recall_score 0.9617834394904459\n",
      "Confusion  matrix:\n",
      " [[  8  25]\n",
      " [  6 151]]\n"
     ]
    }
   ],
   "source": [
    "# XG boost\n",
    "\n",
    "import xgboost\n",
    "xg = xgboost.XGBClassifier()\n",
    "xg.fit(X_train_vectorized, y_train)\n",
    "print(\" XG boost: {: .2f}%\".format(xg.score(X_test_vectorized, y_test)*100))\n",
    "y_pred = xg.predict(X_test_vectorized)\n",
    "print('Accuracy Score: {} / Precision Score {} / recall_score {}'. format(accuracy_score(y_test, y_pred),\n",
    "                                                                      precision_score(y_test, y_pred),\n",
    "                                                                      recall_score(y_test, y_pred)))\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion  matrix:\\n {}'.format(cnf_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary:logistic',\n",
       " 'use_label_encoder': True,\n",
       " 'base_score': 0.5,\n",
       " 'booster': 'gbtree',\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bynode': 1,\n",
       " 'colsample_bytree': 1,\n",
       " 'gamma': 0,\n",
       " 'gpu_id': -1,\n",
       " 'importance_type': 'gain',\n",
       " 'interaction_constraints': '',\n",
       " 'learning_rate': 0.300000012,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 6,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': '()',\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': 8,\n",
       " 'num_parallel_tree': 1,\n",
       " 'random_state': 0,\n",
       " 'reg_alpha': 0,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': 1,\n",
       " 'subsample': 1,\n",
       " 'tree_method': 'exact',\n",
       " 'validate_parameters': 1,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid RandomizedSearchCV will search over\n",
    "grid = {\"n_estimators\": [10, 100, 200, 500, 1000, 1200],\n",
    "        \"max_depth\": [None, 5, 10, 20, 30],\n",
    "        \"learning_rate\": [0.1, 0.3, 0.5, 0.7, 1],\n",
    "        \"min_child_weight\": [2, 4, 6]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] n_estimators=1200, min_child_weight=4, max_depth=10, learning_rate=1 \n",
      "[07:40:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\AYODE\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1200, min_child_weight=4, max_depth=10, learning_rate=1, total=   5.2s\n",
      "[CV] n_estimators=1200, min_child_weight=4, max_depth=10, learning_rate=1 \n",
      "[07:40:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1200, min_child_weight=4, max_depth=10, learning_rate=1, total=   4.8s\n",
      "[CV] n_estimators=1200, min_child_weight=4, max_depth=10, learning_rate=1 \n",
      "[07:40:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1200, min_child_weight=4, max_depth=10, learning_rate=1, total=   4.2s\n",
      "[CV] n_estimators=1200, min_child_weight=4, max_depth=10, learning_rate=1 \n",
      "[07:40:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1200, min_child_weight=4, max_depth=10, learning_rate=1, total=   5.1s\n",
      "[CV] n_estimators=1200, min_child_weight=4, max_depth=10, learning_rate=1 \n",
      "[07:40:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1200, min_child_weight=4, max_depth=10, learning_rate=1, total=   5.7s\n",
      "[CV] n_estimators=10, min_child_weight=6, max_depth=30, learning_rate=1 \n",
      "[07:40:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=10, min_child_weight=6, max_depth=30, learning_rate=1, total=   0.1s\n",
      "[CV] n_estimators=10, min_child_weight=6, max_depth=30, learning_rate=1 \n",
      "[07:40:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=10, min_child_weight=6, max_depth=30, learning_rate=1, total=   0.1s\n",
      "[CV] n_estimators=10, min_child_weight=6, max_depth=30, learning_rate=1 \n",
      "[07:40:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=10, min_child_weight=6, max_depth=30, learning_rate=1, total=   0.1s\n",
      "[CV] n_estimators=10, min_child_weight=6, max_depth=30, learning_rate=1 \n",
      "[07:40:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=10, min_child_weight=6, max_depth=30, learning_rate=1, total=   0.1s\n",
      "[CV] n_estimators=10, min_child_weight=6, max_depth=30, learning_rate=1 \n",
      "[07:40:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=10, min_child_weight=6, max_depth=30, learning_rate=1, total=   0.1s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.3 \n",
      "[07:40:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.3, total=   2.4s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.3 \n",
      "[07:40:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.3, total=   2.2s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.3 \n",
      "[07:40:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.3, total=   1.6s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.3 \n",
      "[07:40:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.3, total=   1.9s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.3 \n",
      "[07:41:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.3, total=   2.2s\n",
      "[CV] n_estimators=10, min_child_weight=6, max_depth=5, learning_rate=0.1 \n",
      "[07:41:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=10, min_child_weight=6, max_depth=5, learning_rate=0.1, total=   0.1s\n",
      "[CV] n_estimators=10, min_child_weight=6, max_depth=5, learning_rate=0.1 \n",
      "[07:41:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=10, min_child_weight=6, max_depth=5, learning_rate=0.1, total=   0.1s\n",
      "[CV] n_estimators=10, min_child_weight=6, max_depth=5, learning_rate=0.1 \n",
      "[07:41:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=10, min_child_weight=6, max_depth=5, learning_rate=0.1, total=   0.1s\n",
      "[CV] n_estimators=10, min_child_weight=6, max_depth=5, learning_rate=0.1 \n",
      "[07:41:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=10, min_child_weight=6, max_depth=5, learning_rate=0.1, total=   0.1s\n",
      "[CV] n_estimators=10, min_child_weight=6, max_depth=5, learning_rate=0.1 \n",
      "[07:41:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=10, min_child_weight=6, max_depth=5, learning_rate=0.1, total=   0.1s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=1 \n",
      "[07:41:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=1, total=   0.4s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=1 \n",
      "[07:41:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=1, total=   0.4s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=1 \n",
      "[07:41:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=1, total=   0.4s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=1 \n",
      "[07:41:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=1, total=   0.4s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=1 \n",
      "[07:41:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=1, total=   0.4s\n",
      "[CV] n_estimators=100, min_child_weight=6, max_depth=20, learning_rate=0.3 \n",
      "[07:41:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=100, min_child_weight=6, max_depth=20, learning_rate=0.3, total=   0.4s\n",
      "[CV] n_estimators=100, min_child_weight=6, max_depth=20, learning_rate=0.3 \n",
      "[07:41:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=100, min_child_weight=6, max_depth=20, learning_rate=0.3, total=   0.4s\n",
      "[CV] n_estimators=100, min_child_weight=6, max_depth=20, learning_rate=0.3 \n",
      "[07:41:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=100, min_child_weight=6, max_depth=20, learning_rate=0.3, total=   0.4s\n",
      "[CV] n_estimators=100, min_child_weight=6, max_depth=20, learning_rate=0.3 \n",
      "[07:41:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=100, min_child_weight=6, max_depth=20, learning_rate=0.3, total=   0.4s\n",
      "[CV] n_estimators=100, min_child_weight=6, max_depth=20, learning_rate=0.3 \n",
      "[07:41:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=100, min_child_weight=6, max_depth=20, learning_rate=0.3, total=   0.4s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=0.7 \n",
      "[07:41:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=0.7, total=   0.4s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=0.7 \n",
      "[07:41:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=0.7, total=   0.4s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=0.7 \n",
      "[07:41:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=0.7, total=   0.4s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=0.7 \n",
      "[07:41:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=0.7, total=   0.4s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=0.7 \n",
      "[07:41:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=0.7, total=   0.3s\n",
      "[CV] n_estimators=500, min_child_weight=6, max_depth=30, learning_rate=1 \n",
      "[07:41:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=500, min_child_weight=6, max_depth=30, learning_rate=1, total=   1.3s\n",
      "[CV] n_estimators=500, min_child_weight=6, max_depth=30, learning_rate=1 \n",
      "[07:41:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=500, min_child_weight=6, max_depth=30, learning_rate=1, total=   1.3s\n",
      "[CV] n_estimators=500, min_child_weight=6, max_depth=30, learning_rate=1 \n",
      "[07:41:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=500, min_child_weight=6, max_depth=30, learning_rate=1, total=   1.4s\n",
      "[CV] n_estimators=500, min_child_weight=6, max_depth=30, learning_rate=1 \n",
      "[07:41:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=500, min_child_weight=6, max_depth=30, learning_rate=1, total=   1.4s\n",
      "[CV] n_estimators=500, min_child_weight=6, max_depth=30, learning_rate=1 \n",
      "[07:41:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=500, min_child_weight=6, max_depth=30, learning_rate=1, total=   1.3s\n",
      "[CV] n_estimators=1000, min_child_weight=6, max_depth=30, learning_rate=0.5 \n",
      "[07:41:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1000, min_child_weight=6, max_depth=30, learning_rate=0.5, total=   2.5s\n",
      "[CV] n_estimators=1000, min_child_weight=6, max_depth=30, learning_rate=0.5 \n",
      "[07:41:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1000, min_child_weight=6, max_depth=30, learning_rate=0.5, total=   2.5s\n",
      "[CV] n_estimators=1000, min_child_weight=6, max_depth=30, learning_rate=0.5 \n",
      "[07:41:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1000, min_child_weight=6, max_depth=30, learning_rate=0.5, total=   2.6s\n",
      "[CV] n_estimators=1000, min_child_weight=6, max_depth=30, learning_rate=0.5 \n",
      "[07:41:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1000, min_child_weight=6, max_depth=30, learning_rate=0.5, total=   3.4s\n",
      "[CV] n_estimators=1000, min_child_weight=6, max_depth=30, learning_rate=0.5 \n",
      "[07:41:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1000, min_child_weight=6, max_depth=30, learning_rate=0.5, total=   4.0s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.7 \n",
      "[07:41:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.7, total=   1.8s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.7 \n",
      "[07:41:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.7, total=   2.0s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.7 \n",
      "[07:41:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.7, total=   2.1s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.7 \n",
      "[07:41:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.7, total=   1.7s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.7 \n",
      "[07:41:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.7, total=   2.0s\n",
      "[CV] n_estimators=1200, min_child_weight=2, max_depth=10, learning_rate=0.3 \n",
      "[07:41:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1200, min_child_weight=2, max_depth=10, learning_rate=0.3, total=   4.4s\n",
      "[CV] n_estimators=1200, min_child_weight=2, max_depth=10, learning_rate=0.3 \n",
      "[07:41:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1200, min_child_weight=2, max_depth=10, learning_rate=0.3, total=   3.3s\n",
      "[CV] n_estimators=1200, min_child_weight=2, max_depth=10, learning_rate=0.3 \n",
      "[07:41:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1200, min_child_weight=2, max_depth=10, learning_rate=0.3, total=   3.2s\n",
      "[CV] n_estimators=1200, min_child_weight=2, max_depth=10, learning_rate=0.3 \n",
      "[07:41:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1200, min_child_weight=2, max_depth=10, learning_rate=0.3, total=   3.7s\n",
      "[CV] n_estimators=1200, min_child_weight=2, max_depth=10, learning_rate=0.3 \n",
      "[07:41:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1200, min_child_weight=2, max_depth=10, learning_rate=0.3, total=   3.5s\n",
      "[CV] n_estimators=1000, min_child_weight=6, max_depth=20, learning_rate=1 \n",
      "[07:41:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1000, min_child_weight=6, max_depth=20, learning_rate=1, total=   2.4s\n",
      "[CV] n_estimators=1000, min_child_weight=6, max_depth=20, learning_rate=1 \n",
      "[07:42:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1000, min_child_weight=6, max_depth=20, learning_rate=1, total=   2.5s\n",
      "[CV] n_estimators=1000, min_child_weight=6, max_depth=20, learning_rate=1 \n",
      "[07:42:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1000, min_child_weight=6, max_depth=20, learning_rate=1, total=   4.0s\n",
      "[CV] n_estimators=1000, min_child_weight=6, max_depth=20, learning_rate=1 \n",
      "[07:42:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1000, min_child_weight=6, max_depth=20, learning_rate=1, total=   2.7s\n",
      "[CV] n_estimators=1000, min_child_weight=6, max_depth=20, learning_rate=1 \n",
      "[07:42:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1000, min_child_weight=6, max_depth=20, learning_rate=1, total=   2.4s\n",
      "[CV] n_estimators=1000, min_child_weight=6, max_depth=20, learning_rate=0.1 \n",
      "[07:42:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1000, min_child_weight=6, max_depth=20, learning_rate=0.1, total=   3.0s\n",
      "[CV] n_estimators=1000, min_child_weight=6, max_depth=20, learning_rate=0.1 \n",
      "[07:42:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1000, min_child_weight=6, max_depth=20, learning_rate=0.1, total=   2.8s\n",
      "[CV] n_estimators=1000, min_child_weight=6, max_depth=20, learning_rate=0.1 \n",
      "[07:42:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1000, min_child_weight=6, max_depth=20, learning_rate=0.1, total=   2.9s\n",
      "[CV] n_estimators=1000, min_child_weight=6, max_depth=20, learning_rate=0.1 \n",
      "[07:42:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1000, min_child_weight=6, max_depth=20, learning_rate=0.1, total=   2.9s\n",
      "[CV] n_estimators=1000, min_child_weight=6, max_depth=20, learning_rate=0.1 \n",
      "[07:42:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1000, min_child_weight=6, max_depth=20, learning_rate=0.1, total=   2.7s\n",
      "[CV] n_estimators=200, min_child_weight=6, max_depth=10, learning_rate=0.3 \n",
      "[07:42:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=200, min_child_weight=6, max_depth=10, learning_rate=0.3, total=   0.6s\n",
      "[CV] n_estimators=200, min_child_weight=6, max_depth=10, learning_rate=0.3 \n",
      "[07:42:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=200, min_child_weight=6, max_depth=10, learning_rate=0.3, total=   0.6s\n",
      "[CV] n_estimators=200, min_child_weight=6, max_depth=10, learning_rate=0.3 \n",
      "[07:42:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=200, min_child_weight=6, max_depth=10, learning_rate=0.3, total=   0.6s\n",
      "[CV] n_estimators=200, min_child_weight=6, max_depth=10, learning_rate=0.3 \n",
      "[07:42:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=200, min_child_weight=6, max_depth=10, learning_rate=0.3, total=   0.6s\n",
      "[CV] n_estimators=200, min_child_weight=6, max_depth=10, learning_rate=0.3 \n",
      "[07:42:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=200, min_child_weight=6, max_depth=10, learning_rate=0.3, total=   0.7s\n",
      "[CV] n_estimators=1000, min_child_weight=4, max_depth=10, learning_rate=0.7 \n",
      "[07:42:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1000, min_child_weight=4, max_depth=10, learning_rate=0.7, total=   2.5s\n",
      "[CV] n_estimators=1000, min_child_weight=4, max_depth=10, learning_rate=0.7 \n",
      "[07:42:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1000, min_child_weight=4, max_depth=10, learning_rate=0.7, total=   2.5s\n",
      "[CV] n_estimators=1000, min_child_weight=4, max_depth=10, learning_rate=0.7 \n",
      "[07:42:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1000, min_child_weight=4, max_depth=10, learning_rate=0.7, total=   2.5s\n",
      "[CV] n_estimators=1000, min_child_weight=4, max_depth=10, learning_rate=0.7 \n",
      "[07:42:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1000, min_child_weight=4, max_depth=10, learning_rate=0.7, total=   2.6s\n",
      "[CV] n_estimators=1000, min_child_weight=4, max_depth=10, learning_rate=0.7 \n",
      "[07:42:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1000, min_child_weight=4, max_depth=10, learning_rate=0.7, total=   2.5s\n",
      "[CV] n_estimators=1000, min_child_weight=6, max_depth=5, learning_rate=0.3 \n",
      "[07:42:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1000, min_child_weight=6, max_depth=5, learning_rate=0.3, total=   2.7s\n",
      "[CV] n_estimators=1000, min_child_weight=6, max_depth=5, learning_rate=0.3 \n",
      "[07:42:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1000, min_child_weight=6, max_depth=5, learning_rate=0.3, total=   2.7s\n",
      "[CV] n_estimators=1000, min_child_weight=6, max_depth=5, learning_rate=0.3 \n",
      "[07:42:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1000, min_child_weight=6, max_depth=5, learning_rate=0.3, total=   2.7s\n",
      "[CV] n_estimators=1000, min_child_weight=6, max_depth=5, learning_rate=0.3 \n",
      "[07:42:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1000, min_child_weight=6, max_depth=5, learning_rate=0.3, total=   2.6s\n",
      "[CV] n_estimators=1000, min_child_weight=6, max_depth=5, learning_rate=0.3 \n",
      "[07:42:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1000, min_child_weight=6, max_depth=5, learning_rate=0.3, total=   3.1s\n",
      "[CV] n_estimators=500, min_child_weight=6, max_depth=10, learning_rate=0.5 \n",
      "[07:42:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=500, min_child_weight=6, max_depth=10, learning_rate=0.5, total=   1.5s\n",
      "[CV] n_estimators=500, min_child_weight=6, max_depth=10, learning_rate=0.5 \n",
      "[07:42:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=500, min_child_weight=6, max_depth=10, learning_rate=0.5, total=   1.8s\n",
      "[CV] n_estimators=500, min_child_weight=6, max_depth=10, learning_rate=0.5 \n",
      "[07:43:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=500, min_child_weight=6, max_depth=10, learning_rate=0.5, total=   1.5s\n",
      "[CV] n_estimators=500, min_child_weight=6, max_depth=10, learning_rate=0.5 \n",
      "[07:43:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=500, min_child_weight=6, max_depth=10, learning_rate=0.5, total=   1.4s\n",
      "[CV] n_estimators=500, min_child_weight=6, max_depth=10, learning_rate=0.5 \n",
      "[07:43:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=500, min_child_weight=6, max_depth=10, learning_rate=0.5, total=   1.3s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=0.1 \n",
      "[07:43:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=0.1, total=   0.6s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=0.1 \n",
      "[07:43:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=0.1, total=   0.6s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=0.1 \n",
      "[07:43:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=0.1, total=   0.6s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=0.1 \n",
      "[07:43:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=0.1, total=   0.6s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=0.1 \n",
      "[07:43:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=20, learning_rate=0.1, total=   0.6s\n",
      "[CV] n_estimators=1000, min_child_weight=2, max_depth=30, learning_rate=0.1 \n",
      "[07:43:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1000, min_child_weight=2, max_depth=30, learning_rate=0.1, total=   3.3s\n",
      "[CV] n_estimators=1000, min_child_weight=2, max_depth=30, learning_rate=0.1 \n",
      "[07:43:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1000, min_child_weight=2, max_depth=30, learning_rate=0.1, total=   3.1s\n",
      "[CV] n_estimators=1000, min_child_weight=2, max_depth=30, learning_rate=0.1 \n",
      "[07:43:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1000, min_child_weight=2, max_depth=30, learning_rate=0.1, total=   3.2s\n",
      "[CV] n_estimators=1000, min_child_weight=2, max_depth=30, learning_rate=0.1 \n",
      "[07:43:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1000, min_child_weight=2, max_depth=30, learning_rate=0.1, total=   3.2s\n",
      "[CV] n_estimators=1000, min_child_weight=2, max_depth=30, learning_rate=0.1 \n",
      "[07:43:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=1000, min_child_weight=2, max_depth=30, learning_rate=0.1, total=   3.6s\n",
      "[CV] n_estimators=500, min_child_weight=2, max_depth=10, learning_rate=0.1 \n",
      "[07:43:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=500, min_child_weight=2, max_depth=10, learning_rate=0.1, total=   1.8s\n",
      "[CV] n_estimators=500, min_child_weight=2, max_depth=10, learning_rate=0.1 \n",
      "[07:43:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=500, min_child_weight=2, max_depth=10, learning_rate=0.1, total=   1.7s\n",
      "[CV] n_estimators=500, min_child_weight=2, max_depth=10, learning_rate=0.1 \n",
      "[07:43:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=500, min_child_weight=2, max_depth=10, learning_rate=0.1, total=   1.7s\n",
      "[CV] n_estimators=500, min_child_weight=2, max_depth=10, learning_rate=0.1 \n",
      "[07:43:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=500, min_child_weight=2, max_depth=10, learning_rate=0.1, total=   1.7s\n",
      "[CV] n_estimators=500, min_child_weight=2, max_depth=10, learning_rate=0.1 \n",
      "[07:43:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  n_estimators=500, min_child_weight=2, max_depth=10, learning_rate=0.1, total=   1.7s\n",
      "[07:43:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  3.1min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set n_jobs to -1 to use all cores (NOTE: n_jobs=-1 is broken as of 8 Dec 2019, using n_jobs=1 works)\n",
    "clf = xgboost.XGBClassifier()\n",
    "\n",
    "# Setup RandomizedSearchCV\n",
    "xg_clf = RandomizedSearchCV(estimator=clf,\n",
    "                            param_distributions=grid,\n",
    "                            n_iter=20, # try 20 models total\n",
    "                            cv=5, # 5-fold cross-validation\n",
    "                            verbose=2) # print out results\n",
    "\n",
    "# Fit the RandomizedSearchCV version of clf\n",
    "xg_clf.fit(X_train_vectorized, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500,\n",
       " 'min_child_weight': 2,\n",
       " 'max_depth': 10,\n",
       " 'learning_rate': 0.1}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:44:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " XG boost:  83.16%\n",
      "Accuracy Score: 0.8315789473684211 / Precision Score 0.8531073446327684 / recall_score 0.9617834394904459\n",
      "Confusion  matrix:\n",
      " [[  7  26]\n",
      " [  6 151]]\n"
     ]
    }
   ],
   "source": [
    "xg = xgboost.XGBClassifier(**xg_clf.best_params_)\n",
    "xg.fit(X_train_vectorized, y_train)\n",
    "print(\" XG boost: {: .2f}%\".format(xg.score(X_test_vectorized, y_test)*100))\n",
    "y_pred = xg.predict(X_test_vectorized)\n",
    "print('Accuracy Score: {} / Precision Score {} / recall_score {}'. format(accuracy_score(y_test, y_pred),\n",
    "                                                                      precision_score(y_test, y_pred),\n",
    "                                                                      recall_score(y_test, y_pred)))\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion  matrix:\\n {}'.format(cnf_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8421052631578947 / Precision Score 0.8547486033519553 / recall_score 0.9745222929936306\n",
      "Confusion  matrix:\n",
      " [[  7  26]\n",
      " [  4 153]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train_vectorized, y_train)\n",
    "y_pred = gb.predict(X_test_vectorized)\n",
    "print('Accuracy Score: {} / Precision Score {} / recall_score {}'. format(accuracy_score(y_test, y_pred),\n",
    "                                                                      precision_score(y_test, y_pred),\n",
    "                                                                      recall_score(y_test, y_pred)))\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion  matrix:\\n {}'.format(cnf_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'criterion': 'friedman_mse',\n",
       " 'init': None,\n",
       " 'learning_rate': 0.1,\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 3,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_iter_no_change': None,\n",
       " 'presort': 'deprecated',\n",
       " 'random_state': None,\n",
       " 'subsample': 1.0,\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid RandomizedSearchCV will search over\n",
    "grid = {\"n_estimators\": [10, 100, 200, 500, 1000, 1200],\n",
    "        \"max_depth\": [None, 5, 10, 20, 30],\n",
    "        \"max_features\": [\"auto\", \"sqrt\"],\n",
    "        \"min_samples_split\": [2, 4, 6],\n",
    "        \"min_samples_leaf\": [1, 2, 4],\n",
    "       \"learning_rate\":[0.1, 1, 10, 20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=10, learning_rate=1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=10, learning_rate=1, total=   0.5s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=10, learning_rate=1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=10, learning_rate=1, total=   0.5s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=10, learning_rate=1 \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=10, learning_rate=1, total=   0.5s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=10, learning_rate=1 \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=10, learning_rate=1, total=   0.5s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=10, learning_rate=1 \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=10, learning_rate=1, total=   0.5s\n",
      "[CV] n_estimators=1000, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=5, learning_rate=10 \n",
      "[CV]  n_estimators=1000, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=5, learning_rate=10, total=   1.6s\n",
      "[CV] n_estimators=1000, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=5, learning_rate=10 \n",
      "[CV]  n_estimators=1000, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=5, learning_rate=10, total=   1.6s\n",
      "[CV] n_estimators=1000, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=5, learning_rate=10 \n",
      "[CV]  n_estimators=1000, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=5, learning_rate=10, total=   1.6s\n",
      "[CV] n_estimators=1000, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=5, learning_rate=10 \n",
      "[CV]  n_estimators=1000, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=5, learning_rate=10, total=   1.9s\n",
      "[CV] n_estimators=1000, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=5, learning_rate=10 \n",
      "[CV]  n_estimators=1000, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=5, learning_rate=10, total=   1.7s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=None, learning_rate=10 \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=None, learning_rate=10, total=   6.7s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=None, learning_rate=10 \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=None, learning_rate=10, total=   7.4s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=None, learning_rate=10 \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=None, learning_rate=10, total=   9.8s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=None, learning_rate=10 \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=None, learning_rate=10, total=   8.4s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=None, learning_rate=10 \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=None, learning_rate=10, total=   8.6s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=None, learning_rate=10 \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=None, learning_rate=10, total=  25.2s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=None, learning_rate=10 \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=None, learning_rate=10, total=  34.0s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=None, learning_rate=10 \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=None, learning_rate=10, total=  33.2s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=None, learning_rate=10 \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=None, learning_rate=10, total=  46.7s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=None, learning_rate=10 \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=None, learning_rate=10, total=  22.7s\n",
      "[CV] n_estimators=10, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=None, learning_rate=20 \n",
      "[CV]  n_estimators=10, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=None, learning_rate=20, total=   0.7s\n",
      "[CV] n_estimators=10, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=None, learning_rate=20 \n",
      "[CV]  n_estimators=10, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=None, learning_rate=20, total=   0.7s\n",
      "[CV] n_estimators=10, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=None, learning_rate=20 \n",
      "[CV]  n_estimators=10, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=None, learning_rate=20, total=   0.7s\n",
      "[CV] n_estimators=10, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=None, learning_rate=20 \n",
      "[CV]  n_estimators=10, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=None, learning_rate=20, total=   0.7s\n",
      "[CV] n_estimators=10, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=None, learning_rate=20 \n",
      "[CV]  n_estimators=10, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=None, learning_rate=20, total=   0.7s\n",
      "[CV] n_estimators=1000, min_samples_split=6, min_samples_leaf=2, max_features=auto, max_depth=30, learning_rate=0.1 \n",
      "[CV]  n_estimators=1000, min_samples_split=6, min_samples_leaf=2, max_features=auto, max_depth=30, learning_rate=0.1, total=  53.4s\n",
      "[CV] n_estimators=1000, min_samples_split=6, min_samples_leaf=2, max_features=auto, max_depth=30, learning_rate=0.1 \n",
      "[CV]  n_estimators=1000, min_samples_split=6, min_samples_leaf=2, max_features=auto, max_depth=30, learning_rate=0.1, total=  53.4s\n",
      "[CV] n_estimators=1000, min_samples_split=6, min_samples_leaf=2, max_features=auto, max_depth=30, learning_rate=0.1 \n",
      "[CV]  n_estimators=1000, min_samples_split=6, min_samples_leaf=2, max_features=auto, max_depth=30, learning_rate=0.1, total=  52.2s\n",
      "[CV] n_estimators=1000, min_samples_split=6, min_samples_leaf=2, max_features=auto, max_depth=30, learning_rate=0.1 \n",
      "[CV]  n_estimators=1000, min_samples_split=6, min_samples_leaf=2, max_features=auto, max_depth=30, learning_rate=0.1, total=  58.2s\n",
      "[CV] n_estimators=1000, min_samples_split=6, min_samples_leaf=2, max_features=auto, max_depth=30, learning_rate=0.1 \n",
      "[CV]  n_estimators=1000, min_samples_split=6, min_samples_leaf=2, max_features=auto, max_depth=30, learning_rate=0.1, total=  58.7s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=5, learning_rate=10 \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=5, learning_rate=10, total=   2.9s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=5, learning_rate=10 \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=5, learning_rate=10, total=   2.4s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=5, learning_rate=10 \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=5, learning_rate=10, total=   2.8s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=5, learning_rate=10 \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=5, learning_rate=10, total=   2.9s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=5, learning_rate=10 \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=5, learning_rate=10, total=   3.3s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=20, learning_rate=0.1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=20, learning_rate=0.1, total=   0.5s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=20, learning_rate=0.1 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=20, learning_rate=0.1, total=   0.5s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=20, learning_rate=0.1 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=20, learning_rate=0.1, total=   0.5s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=20, learning_rate=0.1 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=20, learning_rate=0.1, total=   0.5s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=20, learning_rate=0.1 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=auto, max_depth=20, learning_rate=0.1, total=   0.6s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20, learning_rate=10 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20, learning_rate=10, total=   0.1s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20, learning_rate=10 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20, learning_rate=10, total=   0.1s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20, learning_rate=10 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20, learning_rate=10, total=   0.1s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20, learning_rate=10 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20, learning_rate=10, total=   0.1s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20, learning_rate=10 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20, learning_rate=10, total=   0.1s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, learning_rate=20 \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, learning_rate=20, total=   8.8s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, learning_rate=20 \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, learning_rate=20, total=   7.2s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, learning_rate=20 \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, learning_rate=20, total=   7.4s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, learning_rate=20 \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, learning_rate=20, total=   7.2s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, learning_rate=20 \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, learning_rate=20, total=   7.0s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=5, learning_rate=0.1 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=5, learning_rate=0.1, total=  12.3s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=5, learning_rate=0.1 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=5, learning_rate=0.1, total=  12.4s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=5, learning_rate=0.1 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=5, learning_rate=0.1, total=  12.0s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=5, learning_rate=0.1 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=5, learning_rate=0.1, total=  11.8s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=5, learning_rate=0.1 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=5, learning_rate=0.1, total=  11.5s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=None, learning_rate=20 \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=None, learning_rate=20, total=   6.1s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=None, learning_rate=20 \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=None, learning_rate=20, total=   4.8s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=None, learning_rate=20 \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=None, learning_rate=20, total=   5.5s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=None, learning_rate=20 \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=None, learning_rate=20, total=   8.2s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=None, learning_rate=20 \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=None, learning_rate=20, total=   6.3s\n",
      "[CV] n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10, learning_rate=1 \n",
      "[CV]  n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10, learning_rate=1, total=   1.9s\n",
      "[CV] n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10, learning_rate=1 \n",
      "[CV]  n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10, learning_rate=1, total=   2.0s\n",
      "[CV] n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10, learning_rate=1 \n",
      "[CV]  n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10, learning_rate=1, total=   2.0s\n",
      "[CV] n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10, learning_rate=1 \n",
      "[CV]  n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10, learning_rate=1, total=   2.0s\n",
      "[CV] n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10, learning_rate=1 \n",
      "[CV]  n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10, learning_rate=1, total=   1.9s\n",
      "[CV] n_estimators=500, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=30, learning_rate=10 \n",
      "[CV]  n_estimators=500, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=30, learning_rate=10, total=  28.5s\n",
      "[CV] n_estimators=500, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=30, learning_rate=10 \n",
      "[CV]  n_estimators=500, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=30, learning_rate=10, total=  30.3s\n",
      "[CV] n_estimators=500, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=30, learning_rate=10 \n",
      "[CV]  n_estimators=500, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=30, learning_rate=10, total=  29.3s\n",
      "[CV] n_estimators=500, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=30, learning_rate=10 \n",
      "[CV]  n_estimators=500, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=30, learning_rate=10, total=  33.9s\n",
      "[CV] n_estimators=500, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=30, learning_rate=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=500, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=30, learning_rate=10, total=  30.7s\n",
      "[CV] n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=5, learning_rate=10 \n",
      "[CV]  n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=5, learning_rate=10, total=   7.7s\n",
      "[CV] n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=5, learning_rate=10 \n",
      "[CV]  n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=5, learning_rate=10, total=   7.4s\n",
      "[CV] n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=5, learning_rate=10 \n",
      "[CV]  n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=5, learning_rate=10, total=   6.0s\n",
      "[CV] n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=5, learning_rate=10 \n",
      "[CV]  n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=5, learning_rate=10, total=   6.2s\n",
      "[CV] n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=5, learning_rate=10 \n",
      "[CV]  n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=5, learning_rate=10, total=   6.1s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=20, learning_rate=1 \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=20, learning_rate=1, total=   0.3s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=20, learning_rate=1 \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=20, learning_rate=1, total=   0.3s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=20, learning_rate=1 \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=20, learning_rate=1, total=   0.3s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=20, learning_rate=1 \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=20, learning_rate=1, total=   0.3s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=20, learning_rate=1 \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=20, learning_rate=1, total=   0.3s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=None, learning_rate=10 \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=None, learning_rate=10, total=   0.7s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=None, learning_rate=10 \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=None, learning_rate=10, total=   0.8s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=None, learning_rate=10 \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=None, learning_rate=10, total=   0.8s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=None, learning_rate=10 \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=None, learning_rate=10, total=   0.7s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=None, learning_rate=10 \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=4, max_features=sqrt, max_depth=None, learning_rate=10, total=   0.7s\n",
      "[CV] n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30, learning_rate=0.1 \n",
      "[CV]  n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30, learning_rate=0.1, total=  32.7s\n",
      "[CV] n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30, learning_rate=0.1 \n",
      "[CV]  n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30, learning_rate=0.1, total=  32.6s\n",
      "[CV] n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30, learning_rate=0.1 \n",
      "[CV]  n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30, learning_rate=0.1, total=  34.4s\n",
      "[CV] n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30, learning_rate=0.1 \n",
      "[CV]  n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30, learning_rate=0.1, total=  37.3s\n",
      "[CV] n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30, learning_rate=0.1 \n",
      "[CV]  n_estimators=500, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30, learning_rate=0.1, total=  32.4s\n",
      "[CV] n_estimators=500, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=None, learning_rate=0.1 \n",
      "[CV]  n_estimators=500, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=None, learning_rate=0.1, total=  47.7s\n",
      "[CV] n_estimators=500, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=None, learning_rate=0.1 \n",
      "[CV]  n_estimators=500, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=None, learning_rate=0.1, total=  46.2s\n",
      "[CV] n_estimators=500, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=None, learning_rate=0.1 \n",
      "[CV]  n_estimators=500, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=None, learning_rate=0.1, total=  49.1s\n",
      "[CV] n_estimators=500, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=None, learning_rate=0.1 \n",
      "[CV]  n_estimators=500, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=None, learning_rate=0.1, total=  47.4s\n",
      "[CV] n_estimators=500, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=None, learning_rate=0.1 \n",
      "[CV]  n_estimators=500, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=None, learning_rate=0.1, total=  45.8s\n",
      "[CV] n_estimators=500, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=5, learning_rate=1 \n",
      "[CV]  n_estimators=500, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=5, learning_rate=1, total=   0.8s\n",
      "[CV] n_estimators=500, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=5, learning_rate=1 \n",
      "[CV]  n_estimators=500, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=5, learning_rate=1, total=   0.9s\n",
      "[CV] n_estimators=500, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=5, learning_rate=1 \n",
      "[CV]  n_estimators=500, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=5, learning_rate=1, total=   1.0s\n",
      "[CV] n_estimators=500, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=5, learning_rate=1 \n",
      "[CV]  n_estimators=500, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=5, learning_rate=1, total=   0.8s\n",
      "[CV] n_estimators=500, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=5, learning_rate=1 \n",
      "[CV]  n_estimators=500, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=5, learning_rate=1, total=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed: 20.8min finished\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Set n_jobs to -1 to use all cores (NOTE: n_jobs=-1 is broken as of 8 Dec 2019, using n_jobs=1 works)\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "# Setup RandomizedSearchCV\n",
    "xg_clf = RandomizedSearchCV(estimator=clf,\n",
    "                            param_distributions=grid,\n",
    "                            n_iter=20, # try 20 models total\n",
    "                            cv=5, # 5-fold cross-validation\n",
    "                            verbose=2) # print out results\n",
    "\n",
    "# Fit the RandomizedSearchCV version of clf\n",
    "xg_clf.fit(X_train_vectorized, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500,\n",
       " 'min_samples_split': 4,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 5,\n",
       " 'learning_rate': 1}"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8736842105263158 / Precision Score 0.893491124260355 / recall_score 0.9617834394904459\n",
      "Confusion  matrix:\n",
      " [[ 15  18]\n",
      " [  6 151]]\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(**xg_clf.best_params_)\n",
    "gb.fit(X_train_vectorized, y_train)\n",
    "y_pred = gb.predict(X_test_vectorized)\n",
    "print('Accuracy Score: {} / Precision Score {} / recall_score {}'. format(accuracy_score(y_test, y_pred),\n",
    "                                                                      precision_score(y_test, y_pred),\n",
    "                                                                      recall_score(y_test, y_pred)))\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion  matrix:\\n {}'.format(cnf_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "import pickle\n",
    "with open('model_diabetes','wb')as f:\n",
    "    pickle.dump(xg, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOADING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_diabetes','rb')as f:\n",
    "    mp=pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREDICTING WITH SVED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272           This had been opened previously! Read more\n",
       "645    BUYER BEWARE !!! I received the first Kinect i...\n",
       "670    Wanted to give these a try so I ordered the va...\n",
       "202    The lights are beautiful! 1 did not work at ni...\n",
       "572    I like Kind bars.  They taste good and are hea...\n",
       "593    This flavor is by far my favorite, it tastes j...\n",
       "346    This is very thin and cheap. Do not buy this a...\n",
       "49     I bought the White Hot Chocolate and I have no...\n",
       "48     I will say that this borders on being truly di...\n",
       "52     Absolutely no flavor. For hot white chocolate ...\n",
       "495    It was loud, heavy and not very powerful.  I w...\n",
       "62     I wanted to give Nestle 5 stars. However, afte...\n",
       "735    This is a good product, works perfectly for ND...\n",
       "Name: comments, dtype: object"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[mp.predict(X_test_vectorized) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a good product, works perfectly for NDS roms. Cartridge fit registers everytime. Only docked a star as the website kernel is not explained well, and other emulators on card would not work at all. Read more'"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X_test)[-7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IBM SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson import NaturalLanguageUnderstandingV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "from ibm_watson.natural_language_understanding_v1 import (\n",
    "    Features, CategoriesOptions, \n",
    "    KeywordsOptions, ConceptsOptions, \n",
    "    EntitiesOptions, SentimentOptions, \n",
    "    EmotionOptions,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_key = \"PaF08Entt3viSUwzVxMxN4IDja8vNqFL1OImMrfUb-_c\"\n",
    "authenticator = IAMAuthenticator(ibm_key)\n",
    "natural_language_understanding = NaturalLanguageUnderstandingV1(\n",
    "    version='2020-08-01',\n",
    "    authenticator=authenticator\n",
    ")\n",
    "\n",
    "ibm_service_url = \"https://api.eu-gb.natural-language-understanding.watson.cloud.ibm.com/instances/92d60499-c10a-4da7-bb31-34275275140e\"\n",
    "natural_language_understanding.set_service_url(ibm_service_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=list(X_test)[-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a good product, works perfectly for NDS roms. Cartridge fit registers everytime. Only docked a star as the website kernel is not explained well, and other emulators on card would not work at all. Read more'"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = natural_language_understanding.analyze(\n",
    "    text= text,\n",
    "        features=Features(sentiment=SentimentOptions())\n",
    ").get_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'usage': {'text_units': 1, 'text_characters': 213, 'features': 1},\n",
       " 'sentiment': {'document': {'score': -0.459072, 'label': 'negative'}},\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.042, 'neu': 0.737, 'pos': 0.221, 'compound': 0.831}"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'usage': {'text_units': 1, 'text_characters': 30, 'features': 1},\n",
       " 'sentiment': {'document': {'score': -0.750727, 'label': 'negative'}},\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_2 = 'this product is as good as bad'\n",
    "response_2 = natural_language_understanding.analyze(\n",
    "    text= text_2,\n",
    "        features=Features(sentiment=SentimentOptions())\n",
    ").get_result()\n",
    "response_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.307, 'neu': 0.439, 'pos': 0.254, 'compound': -0.1531}"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid.polarity_scores(text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'usage': {'text_units': 1, 'text_characters': 49, 'features': 1},\n",
       " 'sentiment': {'document': {'score': -0.993998, 'label': 'negative'}},\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_3 = 'extremely bad products that it almost made me cry'\n",
    "response_3 = natural_language_understanding.analyze(\n",
    "    text= text_3,\n",
    "        features=Features(sentiment=SentimentOptions())\n",
    ").get_result()\n",
    "response_3\n",
    "# response_3['sentiment']['document']['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "revies_list = [\n",
    "    'not an issue, product is working',\n",
    "    'an issue, product is not working', \n",
    "    'this product is as good as bad',\n",
    "    'this is bad'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "print(model.predict(vect.transform(revies_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# support vector\n",
    "print(svm.predict(vect.transform(revies_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "print(nb.predict(vect.transform(revies_list).toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#KNN model\n",
    "print(knn.predict(vect.transform(revies_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "print(rf.predict(vect.transform(revies_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# XG boost\n",
    "print(xg.predict(vect.transform(revies_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostingClassifier\n",
    "print(gb.predict(vect.transform(revies_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs: \n",
      "['white' 'all' 'again' 'for' 'this' 'just' 'now' 'get' 'be' 'as']\n",
      "\n",
      "Largest Coefs: \n",
      "['so' 'great' 'my' 'two' 'have' 'without' 'butter' 'price' 'one' 'to']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the feature names as numpy array\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "# Sort the coefficients from the model\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "# Find the 10 smallest and 10 largest coefficients\n",
    "# The 10 largest coefficients are being indexed using [:-11:-1] \n",
    "# so the list returned is in order of largest to smallest\n",
    "print('Smallest Coefs: \\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}\\n'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tfidf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Fit the TfidfVectorizer to the training data specifiying a minimum document frequency of 5\n",
    "vect = TfidfVectorizer(min_df = 5).fit(X_train)\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.5\n"
     ]
    }
   ],
   "source": [
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Tfidf: \n",
      "['highly' 'needed' 'whole' 'lot' 'full' 'stars' 'makes' 'purchased' 'off'\n",
      " 'tried']\n",
      "\n",
      "Largest Tfidf: \n",
      "['excellent' 'we' 'more' 'read' 'oz' 'used' 'their' 'was' 'for' 'powder']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "sorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()\n",
    "\n",
    "print('Smallest Tfidf: \\n{}\\n'.format(feature_names[sorted_tfidf_index[:10]]))\n",
    "print('Largest Tfidf: \\n{}\\n'.format(feature_names[sorted_tfidf_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest coef: \n",
      "['white' 'like' 'cups' 'the' 'all' 'do' 'was' 'again' 'now' 'as']\n",
      "\n",
      "Largest coef: \n",
      "['cacao' 'excellent' 'great' 'we' 'price' 'their' 'two' 'butter' 'so'\n",
      " 'per']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "print('Smallest coef: \\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest coef: \\n{}\\n'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "# These reviews are treated the same by our current model\n",
    "\n",
    "print(model.predict(vect.transform(['Not an issue, phone is working', \n",
    "                                   'an issue, phone is not working'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n-grams\n",
    "# Fit the CountVectorizer to the training data specifiying a minimum \n",
    "# document frequency of 5 and extracting 1-grams and 2-grams\n",
    "vect = CountVectorizer(min_df = 5, ngram_range = (1,2)).fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.948236892649\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coef: \n",
      "['sweetener' 'had to' 'can' 'perfect' 'all' 'company' 'since' 'again'\n",
      " 'just' 'and then']\n",
      "\n",
      "Largest Coef: \n",
      "['box' 'delicious' 'find' 'some' 'mix' 'powder' 'received' 'bit' 'of the'\n",
      " 'many']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "print('Smallest Coef: \\n{}\\n'.format(feature_names[sorted_coef_index][:10]))\n",
    "print('Largest Coef: \\n{}\\n'.format(feature_names[sorted_coef_index][:-11:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(vect.transform(['not an issue, phone is working',\n",
    "                                   'an issue, phone is not working'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
